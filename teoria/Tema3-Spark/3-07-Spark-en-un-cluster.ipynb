{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecución de un programa Spark en un cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comando `spark-submit`\n",
    "\n",
    "-   Permite lanzar programas Spark a un cluster\n",
    "\n",
    "- Configuración (**NO** como usuario `root`, sino como usuario normal `luser`):\n",
    "\n",
    "  1. Si la distribución no permite usar `pip`, hay que crear un entorno virtual y activarlo:\n",
    "\n",
    "  ```sh\n",
    "  $ python3 -m venv .venv\n",
    "  $ source .venv/bin/activate\n",
    "  ```\n",
    "  (después instalar `pyspark` con `pip install pyspark`),\n",
    "\n",
    "  2. Recordad que primero hay que hacer visible el script `spark-submit` si se ha instalado desde `pip`:\n",
    "\n",
    "  ```sh\n",
    "  $ export PATH=~/.local/bin:$PATH\n",
    "  ```\n",
    "\n",
    "  3. Y hay que ajustar el valor de la variable de entorno `HADOOP_CONF_DIR` para que apunte al directorio de configuración de Hadoop:\n",
    "\n",
    "  ```sh\n",
    "  $ export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\n",
    "  ```\n",
    "  \n",
    "  4. Si se quiere conectar con jupyter o con visual studio code de forma remota, hay que instalar también el paquete `jupyter` con pip e iniciar el servidor jupyter. También hay que asegurarse de que el contenedor exporta el puerto 8888 (opción `-p 8888:8888` en el comando `docker run`):\n",
    "\n",
    "  ```sh\n",
    "  $ pip install jupyter\n",
    "  $ jupyter notebook --ip=0.0.0.0\n",
    "  ...\n",
    "      To access the server copy and paste one of these URLs:\n",
    "        http://127.0.0.1:8888/tree?token=45447...\n",
    "  ```\n",
    "\n",
    "La dirección `http` que muestra se puede usar para conectar al servidor usando Visual Studio Code seleccionando un \"Existing Jupyter Server\".  \n",
    "\n",
    "Las líneas 2 y 3 se pueden añadir al principio del fichero `.bashrc` para que se ejecuten automáticamente al abrir una terminal.\n",
    "\n",
    "-   Ejemplo:\n",
    "```sh\n",
    "$ spark-submit --master yarn --deploy-mode cluster \\  \n",
    "     --py-files otralib.zip,otrofich.py \\  \n",
    "     --num-executors 10 --executor-cores 2 \\  \n",
    "     mi-script.py opciones_del_script\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opciones de `spark-submit`\n",
    "\n",
    "-   `master`: cluster manager a usar (opciones: `yarn`, `mesos://host:port`, `spark://host:port`, `local[n]`)\n",
    "\n",
    "-   `deploy-mode`: dos modos de despliegue\n",
    "\n",
    "    -   `client`: ejecuta el driver en el nodo local\n",
    "\n",
    "    -   `cluster`: ejecuta el driver en un nodo del cluster\n",
    "\n",
    "-   `class`: clase a ejecutar (Java o Scala)\n",
    "\n",
    "-   `name`: nombre de la aplicación (se muestra en el Spark web)\n",
    "\n",
    "-   `jars`: ficheros jar a añadir al classpath (Java o Scala)\n",
    "\n",
    "-   `py-files`: archivos a añadir al PYTHONPATH (`.py`,`.zip`,`.egg`)\n",
    "\n",
    "-   `files`: ficheros de datos para la aplicación\n",
    "\n",
    "-   `executor-memory`: memoria total de cada ejecutor\n",
    "\n",
    "-   `driver-memory`: memoria del proceso driver\n",
    "\n",
    "Para más opciones: `spark-submit --help`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "text/plain"
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "spark-submit --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "![Modo cliente](http://persoal.citius.usc.es/tf.pena/TCDM/figs/client-mode.jpeg \"Modo cliente en YARN\")\n",
    "\n",
    "![Modo cluster](http://persoal.citius.usc.es/tf.pena/TCDM/figs/cluster-mode.jpeg \"Modo cluster en YARN\")\n",
    "\n",
    "Fuente: [Spark-on-YARN: Empower Spark Applications on Hadoop Cluster](https://www.slideshare.net/Hadoop_Summit/sparkonyarn-empower-spark-applications-on-hadoop-cluster)\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetros de configuración\n",
    "\n",
    "Diversos parámetros ajustables en tiempo de ejecución\n",
    "\n",
    "-   En el script\n",
    "\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "# Creamos un objeto SparkSession (o lo obtenemos si ya está creado)\n",
    "spark: SparkSession = SparkSession \\\n",
    "  .builder \\\n",
    "  .appName(\"Mi aplicacion\") \\\n",
    "  .master(\"local[2]\") \\ # Cluster manager modo local con 2 hilos\n",
    "  .getOrCreate()\n",
    "# Obtenemos el SparkContext\n",
    "sc: SparkContext = spark.sparkContext\n",
    "```\n",
    "\n",
    "-   Mediante flags en el `spark-submit`\n",
    "```sh\n",
    "$ spark-submit --master local[2] --name \"Mi apli\" mi-script.py\n",
    "```    \n",
    "    \n",
    "-   Mediante un fichero de propiedades:\n",
    "```sh\n",
    "$ cat config.conf\n",
    "spark.master     local[2] \n",
    "spark.app.name   \"Mi apli\" \n",
    "spark.ui.port 4040\n",
    "$ spark-submit --properties-file config.conf mi-script.py\n",
    "```\n",
    "\n",
    "Más info: <http://spark.apache.org/docs/latest/configuration.html#spark-properties>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de ejecución de un script Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "text/plain",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile \"/tmp/miscript.py\"\n",
    "# -*- coding: utf-8; -*-\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum,col\n",
    "\n",
    "def main():\n",
    "    spark: SparkSession = SparkSession \\\n",
    "      .builder \\\n",
    "      .appName(\"Mi script Python\") \\\n",
    "      .getOrCreate()\n",
    "\n",
    "    # Cambio la verbosidad para reducir el número de\n",
    "    # mensajes por pantalla\n",
    "    spark.sparkContext.setLogLevel(\"FATAL\")\n",
    "\n",
    "    df1 = spark.range(2, 10000000, 2)\n",
    "    df2 = spark.range(2, 10000000, 4)\n",
    "    step1 = df1.repartition(5)\n",
    "    step12 = df2.repartition(6)\n",
    "    step2 = step1.selectExpr(\"id * 5 as id\")\n",
    "    step3 = step2.join(step12, [\"id\"])\n",
    "    step4 = step3.select(sum(col(\"id\")))\n",
    "\n",
    "    # step4 es un dataframe con una única fila\n",
    "    # que es un objeto Row.\n",
    "    # Con collect() obtengo la fila como una lista\n",
    "    # me quedo con el primer elemento (Row) de la lista\n",
    "    # y lo convierto a un diccionario Python\n",
    "    salida = step4.collect()[0].asDict()['sum(id)']\n",
    "    print(\"Resultado final = {0}\".format(salida))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "text/plain"
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "cat /tmp/miscript.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "format": "text/plain"
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "spark-submit --master local[8] /tmp/miscript.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente lanza la aplicación en el clúster. El modo de deploy se ha dejado en local, por lo que el máster se ejecuta en local y producirá la misma salida que el de arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# Para lanzarlo en el clúster:\n",
    "#spark-submit --master yarn /tmp/miscript.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se ejecuta con el deployment en el clúster no se muestran los resultados, y hay que acceder a los logs en la web del YARN, o bien con un comando para ver los logs de YARN:\n",
    "\n",
    "```sh\n",
    "$ yarn logs -applicationId <application_id>\n",
    "```\n",
    "\n",
    "(donde `<application_id>` es el ID de la aplicación que se muestra en la salida de `spark-submit`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "#spark-submit --master yarn --deploy-mode cluster /tmp/miscript.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
