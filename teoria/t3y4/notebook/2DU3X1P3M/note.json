{
  "paragraphs": [
    {
      "text": "%md\n# Operaciones básicas en Spark\n- Spark opera con colecciones inmutables y distribuidas de elementos, manipulándolos en paralelo\n    - API estructurada: DataFrames y DataSets \n    - API de bajo nivel: RDDs\n\n-   Operaciones sobre estas colecciones \n    -   Creación\n    -   Transformaciones (ordenación, filtrado, etc.)\n    -   Realización acciones para obtener resultados\n\n-   Spark automáticamente distribuye los datos y paraleliza las operaciones",
      "user": "anonymous",
      "dateUpdated": "2020-06-08 19:36:01.772",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eOperaciones básicas en Spark\u003c/h1\u003e\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eSpark opera con colecciones inmutables y distribuidas de elementos, manipulándolos en paralelo\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eAPI estructurada: DataFrames y DataSets\u003c/li\u003e\n      \u003cli\u003eAPI de bajo nivel: RDDs\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eOperaciones sobre estas colecciones \u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eCreación\u003c/li\u003e\n      \u003cli\u003eTransformaciones (ordenación, filtrado, etc.)\u003c/li\u003e\n      \u003cli\u003eRealización acciones para obtener resultados\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eSpark automáticamente distribuye los datos y paraleliza las operaciones\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538585728440_-1456353800",
      "id": "20181003-165528_1966780180",
      "dateCreated": "2018-10-03 16:55:28.000",
      "dateStarted": "2020-06-08 19:36:01.781",
      "dateFinished": "2020-06-08 19:36:01.820",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Ejemplo: creación de un DataFrame a partir de un fichero CSV\nEn este ejemplo, Spark infiere el esquema de los datos de forma automática\n\n  - Es preferible especificar el esquema de forma explícita, como veremos más adelante\n\nTambién se especifica que la primera línea es la cabecera",
      "user": "anonymous",
      "dateUpdated": "2020-06-05 19:49:45.515",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEjemplo: creación de un DataFrame a partir de un fichero CSV\u003c/h3\u003e\n\u003cp\u003eEn este ejemplo, Spark infiere el esquema de los datos de forma automática\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eEs preferible especificar el esquema de forma explícita, como veremos más adelante\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTambién se especifica que la primera línea es la cabecera\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538586109248_610745022",
      "id": "20181003-170149_437390709",
      "dateCreated": "2018-10-03 17:01:49.000",
      "dateStarted": "2018-10-03 17:20:06.000",
      "dateFinished": "2018-10-03 17:20:06.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\nls -lh /datos/2015-summary.csv\nhead /datos/2015-summary.csv",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:28:38.627",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sh"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1538572053914_1310329970",
      "id": "20181003-130733_987750218",
      "dateCreated": "2018-10-03 13:07:33.000",
      "dateStarted": "2020-11-16 15:28:38.694",
      "dateFinished": "2020-11-16 15:28:40.842",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ndatosVuelos2015 \u003d (spark\n    .read\n    .option(\"inferSchema\", \"true\")\n    .option(\"header\", \"true\")\n    .csv(\"/datos/2015-summary.csv\"))",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:29:44.002",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1538579701657_1205777799",
      "id": "20181003-151501_924785435",
      "dateCreated": "2018-10-03 15:15:01.000",
      "dateStarted": "2020-11-16 15:29:44.053",
      "dateFinished": "2020-11-16 15:29:46.871",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\nval datosVuelos2015 \u003d spark.\n        read.\n        option(\"inferSchema\", \"true\").\n        option(\"header\", \"true\").\n        csv(\"/datos/2015-summary.csv\")",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:29:53.226",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1538586195538_-874278150",
      "id": "20181003-170315_1677779682",
      "dateCreated": "2018-10-03 17:03:15.000",
      "dateStarted": "2020-11-16 15:29:53.276",
      "dateFinished": "2020-11-16 15:29:53.825",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ndatosVuelos2015.printSchema()",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:30:17.458",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542038360887_-1243627283",
      "id": "20181112-155920_1582170677",
      "dateCreated": "2018-11-12 15:59:20.000",
      "dateStarted": "2020-11-16 15:30:17.507",
      "dateFinished": "2020-11-16 15:30:17.576",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ndatosVuelos2015.show()\nprint(datosVuelos2015.count())",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:38:06.474",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python",
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1538587224730_-184049219",
      "id": "20181003-172024_1997221051",
      "dateCreated": "2018-10-03 17:20:24.000",
      "dateStarted": "2020-11-16 15:38:06.508",
      "dateFinished": "2020-11-16 15:38:06.755",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\ndatosVuelos2015.show(5)",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:31:23.395",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1538587307261_-542782487",
      "id": "20181003-172147_1618021374",
      "dateCreated": "2018-10-03 17:21:47.000",
      "dateStarted": "2020-11-16 15:31:23.447",
      "dateFinished": "2020-11-16 15:31:23.755",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Rows\n\nLas filas de un DataFrame son objetos de tipo `Row`\n\n- API de Row en Python: http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Row\n- API de Row en Scala: https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row",
      "user": "anonymous",
      "dateUpdated": "2020-06-05 19:49:55.331",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eRows\u003c/h3\u003e\n\u003cp\u003eLas filas de un DataFrame son objetos de tipo \u003ccode\u003eRow\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eAPI de Row en Python: \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Row\"\u003ehttp://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Row\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003eAPI de Row en Scala: \u003ca href\u003d\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row\"\u003ehttps://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Row\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1541354054220_-1636195968",
      "id": "20181104-175414_2052167525",
      "dateCreated": "2018-11-04 17:54:14.000",
      "dateStarted": "2018-11-05 11:54:14.000",
      "dateFinished": "2018-11-05 11:54:14.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Obtenemos las dos primeras fila del DataFrame\nrow1_2 \u003d datosVuelos2015.take(2)\nprint(row1_2)\nprint(type(row1_2))\nprint(type(row1_2[0]))",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:33:10.742",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1541354111850_1607106965",
      "id": "20181104-175511_1019636775",
      "dateCreated": "2018-11-04 17:55:11.000",
      "dateStarted": "2020-11-16 15:33:10.783",
      "dateFinished": "2020-11-16 15:33:10.904",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n\n\n\n\n// Obtenemos las dos primeras fila del DataFrame\n\nval row1_2 \u003d datosVuelos2015.take(2)",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:33:29.903",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1541417928189_-1461046892",
      "id": "20181105-113848_678485134",
      "dateCreated": "2018-11-05 11:38:48.000",
      "dateStarted": "2020-11-16 15:33:29.950",
      "dateFinished": "2020-11-16 15:33:30.274",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Obtén la primera fila como un diccionario Python\nprint(row1_2[0].asDict())\nprint(type(row1_2[0].asDict()))\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:34:00.581",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1541417669542_-992349393",
      "id": "20181105-113429_484087130",
      "dateCreated": "2018-11-05 11:34:29.000",
      "dateStarted": "2020-11-16 15:34:00.619",
      "dateFinished": "2020-11-16 15:34:00.686",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n// Obten la primera fila como un Sequence de Scala\nrow1_2(0).toSeq",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:34:18.164",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1541417964966_1413525265",
      "id": "20181105-113924_2030061794",
      "dateCreated": "2018-11-05 11:39:24.000",
      "dateStarted": "2020-11-16 15:34:18.201",
      "dateFinished": "2020-11-16 15:34:18.455",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Particiones\n\nSpark divide las filas DataFrame (o es su caso en DataSet o el RDD) en un conjunto de particiones\n\n-   El número de particiones por defecto es función del tamaño del cluster (número total de cores en todos los ejecutores) y del tamaño de los datos (número de bloques de los ficheros en HDFS)\n-   Para RDDs se puede especificar otro valor en el momento de crearlos\n-   También se puede modificar una vez creados",
      "user": "anonymous",
      "dateUpdated": "2020-06-05 19:49:57.529",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eParticiones\u003c/h3\u003e\n\u003cp\u003eSpark divide las filas DataFrame (o es su caso en DataSet o el RDD) en un conjunto de particiones\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eEl número de particiones por defecto es función del tamaño del cluster (número total de cores en todos los ejecutores) y del tamaño de los datos (número de bloques de los ficheros en HDFS)\u003c/li\u003e\n  \u003cli\u003ePara RDDs se puede especificar otro valor en el momento de crearlos\u003c/li\u003e\n  \u003cli\u003eTambién se puede modificar una vez creados\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538587344893_-1808639503",
      "id": "20181003-172224_1239915785",
      "dateCreated": "2018-10-03 17:22:24.000",
      "dateStarted": "2018-11-06 09:27:59.000",
      "dateFinished": "2018-11-06 09:27:59.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nprint(\"Número de particiones: {0}\"\n    .format(datosVuelos2015.rdd.getNumPartitions()))\n\n# Creo un nuevo DataFrame con 4 particiones\ndatosVuelos2015_4P \u003d datosVuelos2015.repartition(4)\nprint(\"Número de particiones: {0}\"\n    .format(datosVuelos2015_4P.rdd.getNumPartitions()))",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:36:48.714",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1538587434726_232193119",
      "id": "20181003-172354_1652948106",
      "dateCreated": "2018-10-03 17:23:54.000",
      "dateStarted": "2020-11-16 15:36:48.752",
      "dateFinished": "2020-11-16 15:36:48.936",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\nprintln(\"Número de particiones: \"+\n    datosVuelos2015.rdd.getNumPartitions)\n\nval datosVuelos2015_4P \u003d datosVuelos2015.repartition(4)\nprintln(\"Número de particiones: \"+\n    datosVuelos2015_4P.rdd.getNumPartitions)",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:37:23.612",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1538587504408_-1386567679",
      "id": "20181003-172504_236761339",
      "dateCreated": "2018-10-03 17:25:04.000",
      "dateStarted": "2020-11-16 15:37:23.655",
      "dateFinished": "2020-11-16 15:37:24.063",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Transformaciones\n\nOperaciones que transforman los datos\n\n  - No modifican los datos de origen ( *inmutabilidad* )\n  - Se computan de forma “perezosa” ( *lazyness* )\n\nDos tipos:\n\n  - Transformaciones *estrechas* (narrow)\n    - Cada partición de entrada contribuye a una única partición de salida\n    - No se modifica el número de particiones\n    - Normalmente se realizan en memoria\n  - Transformaciones *anchas* (wide)\n    - Cada partición de salida depende de varias (o todas) particiones de entrada\n    - Suponen un barajado de datos\n    - Pueden implicar un cambio en el número de particiones\n    - Pueden suponer escrituras en disco",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:41:48.392",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eTransformaciones\u003c/h3\u003e\n\u003cp\u003eOperaciones que transforman los datos\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eNo modifican los datos de origen ( \u003cem\u003einmutabilidad\u003c/em\u003e )\u003c/li\u003e\n  \u003cli\u003eSe computan de forma “perezosa” ( \u003cem\u003elazyness\u003c/em\u003e )\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDos tipos:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eTransformaciones \u003cem\u003eestrechas\u003c/em\u003e (narrow)\n    \u003cul\u003e\n      \u003cli\u003eCada partición de entrada contribuye a una única partición de salida\u003c/li\u003e\n      \u003cli\u003eNo se modifica el número de particiones\u003c/li\u003e\n      \u003cli\u003eNormalmente se realizan en memoria\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eTransformaciones \u003cem\u003eanchas\u003c/em\u003e (wide)\n    \u003cul\u003e\n      \u003cli\u003eCada partición de salida depende de varias (o todas) particiones de entrada\u003c/li\u003e\n      \u003cli\u003eSuponen un barajado de datos\u003c/li\u003e\n      \u003cli\u003ePueden implicar un cambio en el número de particiones\u003c/li\u003e\n      \u003cli\u003ePueden suponer escrituras en disco\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538587760815_-725613690",
      "id": "20181003-172920_380831580",
      "dateCreated": "2018-10-03 17:29:20.000",
      "dateStarted": "2020-11-16 15:41:48.392",
      "dateFinished": "2020-11-16 15:41:48.411",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Ejemplo de una transformación narrow\ndatosVuelos2015_EEUU \u003d datosVuelos2015\\\n    .replace(\"United States\", \"Estados Unidos\")",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:44:07.852",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1538579847756_972559521",
      "id": "20181003-151727_320760445",
      "dateCreated": "2018-10-03 15:17:27.000",
      "dateStarted": "2020-11-16 15:44:07.893",
      "dateFinished": "2020-11-16 15:44:07.962",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n// Ejemplo de una transformación narrow\nval datosVuelos2015_EEUU \u003d datosVuelos2015.na.\n    replace(\"*\", Map(\"United States\" -\u003e \"Estados Unidos\"))",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:44:24.099",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "datosVuelos2015_EEUU: org.apache.spark.sql.DataFrame \u003d [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538588992441_-1948939036",
      "id": "20181003-174952_521184149",
      "dateCreated": "2018-10-03 17:49:52.000",
      "dateStarted": "2020-11-16 15:44:24.129",
      "dateFinished": "2020-11-16 15:44:24.724",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Ejemplo de una transformación wide\ndatosVuelos2015_Ord \u003d datosVuelos2015_EEUU\\\n    .sort(\"count\", ascending\u003dFalse)\ndatosVuelos2015_Ord.cache()",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:44:47.879",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: int]"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538589440754_-1201465147",
      "id": "20181003-175720_17358628",
      "dateCreated": "2018-10-03 17:57:20.000",
      "dateStarted": "2020-11-16 15:44:47.912",
      "dateFinished": "2020-11-16 15:44:48.250",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n// Ejemplo de una transformación wide\nval datosVuelos2015_Ord \u003d datosVuelos2015_EEUU.\n    sort($\"count\".desc).cache",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:44:52.547",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "datosVuelos2015_Ord: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538589584069_-1882909311",
      "id": "20181003-175944_1513007453",
      "dateCreated": "2018-10-03 17:59:44.000",
      "dateStarted": "2020-11-16 15:44:52.573",
      "dateFinished": "2020-11-16 15:44:52.921",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Acciones\n\nObtienen un resultado, forzando a que se realicen las transformaciones pendientes\n\n  - En el momento de disparar la *acción* se crea un *plan* con las transformaciones necesarias para obtener los datos solicitados\n    - Se crea un Grafo Dirigido Acíclico (DAG) conectando las transformaciones\n    - Spark optimiza ese grafo, para eliminar transformaciones innecesarias o unir las que sea posible\n  - Las acciones traducen el DAG en un plan de ejecución\n\nTipos de acciones\n\n  - Acciones para mostrar datos por consola\n  - Acciones para convertir datos Spark en datos del lenguaje\n  - Acciones para escribir datos a disco\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-05 19:50:03.178",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eAcciones\u003c/h3\u003e\n\u003cp\u003eObtienen un resultado, forzando a que se realicen las transformaciones pendientes\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eEn el momento de disparar la \u003cem\u003eacción\u003c/em\u003e se crea un \u003cem\u003eplan\u003c/em\u003e con las transformaciones necesarias para obtener los datos solicitados\n    \u003cul\u003e\n      \u003cli\u003eSe crea un Grafo Dirigido Acíclico (DAG) conectando las transformaciones\u003c/li\u003e\n      \u003cli\u003eSpark optimiza ese grafo, para eliminar transformaciones innecesarias o unir las que sea posible\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eLas acciones traducen el DAG en un plan de ejecución\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTipos de acciones\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eAcciones para mostrar datos por consola\u003c/li\u003e\n  \u003cli\u003eAcciones para convertir datos Spark en datos del lenguaje\u003c/li\u003e\n  \u003cli\u003eAcciones para escribir datos a disco\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538589882524_1192221393",
      "id": "20181003-180442_545131369",
      "dateCreated": "2018-10-03 18:04:42.000",
      "dateStarted": "2018-10-03 18:11:00.000",
      "dateFinished": "2018-10-03 18:11:00.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Ejemplo de acciones\nprint(\"Número de filas en la tabla: {0}\"\n    .format(datosVuelos2015_Ord.count()))\n\nprint(datosVuelos2015_Ord.take(3))\n\ndatosVuelos2015_Ord.show()",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:50:36.182",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Número de filas en la tabla: 256\n[Row(DEST_COUNTRY_NAME\u003du\u0027Estados Unidos\u0027, ORIGIN_COUNTRY_NAME\u003du\u0027Estados Unidos\u0027, count\u003d370002), Row(DEST_COUNTRY_NAME\u003du\u0027Estados Unidos\u0027, ORIGIN_COUNTRY_NAME\u003du\u0027Canada\u0027, count\u003d8483), Row(DEST_COUNTRY_NAME\u003du\u0027Canada\u0027, ORIGIN_COUNTRY_NAME\u003du\u0027Estados Unidos\u0027, count\u003d8399)]\n+------------------+-------------------+------+\n| DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n+------------------+-------------------+------+\n|    Estados Unidos|     Estados Unidos|370002|\n|    Estados Unidos|             Canada|  8483|\n|            Canada|     Estados Unidos|  8399|\n|    Estados Unidos|             Mexico|  7187|\n|            Mexico|     Estados Unidos|  7140|\n|    United Kingdom|     Estados Unidos|  2025|\n|    Estados Unidos|     United Kingdom|  1970|\n|             Japan|     Estados Unidos|  1548|\n|    Estados Unidos|              Japan|  1496|\n|           Germany|     Estados Unidos|  1468|\n|    Estados Unidos| Dominican Republic|  1420|\n|Dominican Republic|     Estados Unidos|  1353|\n|    Estados Unidos|            Germany|  1336|\n|       South Korea|     Estados Unidos|  1048|\n|    Estados Unidos|        The Bahamas|   986|\n|       The Bahamas|     Estados Unidos|   955|\n|    Estados Unidos|             France|   952|\n|            France|     Estados Unidos|   935|\n|    Estados Unidos|              China|   920|\n|          Colombia|     Estados Unidos|   873|\n+------------------+-------------------+------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538579890461_1191769990",
      "id": "20181003-151810_859305043",
      "dateCreated": "2018-10-03 15:18:10.000",
      "dateStarted": "2020-11-16 15:50:36.211",
      "dateFinished": "2020-11-16 15:50:36.788",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\nprintln(\"Número de filas en la tabla: \" + datosVuelos2015.count)\nval l \u003d datosVuelos2015.take(3)\n\ndatosVuelos2015_Ord.show",
      "user": "anonymous",
      "dateUpdated": "2020-11-16 15:50:51.324",
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Número de filas en la tabla: 256\n+------------------+-------------------+------+\n| DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n+------------------+-------------------+------+\n|    Estados Unidos|     Estados Unidos|370002|\n|    Estados Unidos|             Canada|  8483|\n|            Canada|     Estados Unidos|  8399|\n|    Estados Unidos|             Mexico|  7187|\n|            Mexico|     Estados Unidos|  7140|\n|    United Kingdom|     Estados Unidos|  2025|\n|    Estados Unidos|     United Kingdom|  1970|\n|             Japan|     Estados Unidos|  1548|\n|    Estados Unidos|              Japan|  1496|\n|           Germany|     Estados Unidos|  1468|\n|    Estados Unidos| Dominican Republic|  1420|\n|Dominican Republic|     Estados Unidos|  1353|\n|    Estados Unidos|            Germany|  1336|\n|       South Korea|     Estados Unidos|  1048|\n|    Estados Unidos|        The Bahamas|   986|\n|       The Bahamas|     Estados Unidos|   955|\n|    Estados Unidos|             France|   952|\n|            France|     Estados Unidos|   935|\n|    Estados Unidos|              China|   920|\n|          Colombia|     Estados Unidos|   873|\n+------------------+-------------------+------+\nonly showing top 20 rows\n\nl: Array[org.apache.spark.sql.Row] \u003d Array([United States,Romania,15], [United States,Croatia,1], [United States,Ireland,344])\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1538580649198_915919210",
      "id": "20181003-153049_1920932374",
      "dateCreated": "2018-10-03 15:30:49.000",
      "dateStarted": "2020-11-16 15:50:51.354",
      "dateFinished": "2020-11-16 15:50:51.796",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark",
      "user": "anonymous",
      "dateUpdated": "2020-11-05 16:53:33.681",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1542040072194_-1763161920",
      "id": "20181112-162752_645954839",
      "dateCreated": "2018-11-12 16:27:52.000",
      "dateStarted": "2020-11-05 16:53:08.672",
      "dateFinished": "2020-11-05 16:53:23.555",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-05 16:53:08.602",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1604595188596_-781138905",
      "id": "20201105-165308_686776663",
      "dateCreated": "2020-11-05 16:53:08.596",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Apache Spark/02 - Operaciones básicas en Spark",
  "id": "2DU3X1P3M",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "sh:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}