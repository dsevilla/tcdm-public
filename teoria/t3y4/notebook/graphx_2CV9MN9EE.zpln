{
  "paragraphs": [
    {
      "text": "%md\n## GraphX: procesamiento de grafos con RDDs\n\nProgramación paralela de grafos con Spark\n\n-   Principal abstracción: [*Graph*](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.graphx.Graph)\n    -   Multigrafo dirigido con propiedades asignadas a vértices y aristas\n    -   Extensión de los RDDs\n- Incluye constructores de grafos, operadores básicos ( *reverse*, *subgraph*…) y algoritmos de grafos ( *PageRank*, *Triangle Counting*…)\n- Solo disponible en Scala\n\nDocumentación: http://spark.apache.org/docs/latest/graphx-programming-guide.html\nAPI: https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.graphx.package",
      "user": "anonymous",
      "dateUpdated": "2020-06-06 20:45:43.024",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eGraphX: procesamiento de grafos con RDDs\u003c/h2\u003e\n\u003cp\u003eProgramación paralela de grafos con Spark\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003ePrincipal abstracción: \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.graphx.Graph\"\u003e\u003cem\u003eGraph\u003c/em\u003e\u003c/a\u003e\n    \u003cul\u003e\n      \u003cli\u003eMultigrafo dirigido con propiedades asignadas a vértices y aristas\u003c/li\u003e\n      \u003cli\u003eExtensión de los RDDs\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eIncluye constructores de grafos, operadores básicos ( \u003cem\u003ereverse\u003c/em\u003e, \u003cem\u003esubgraph\u003c/em\u003e…) y algoritmos de grafos ( \u003cem\u003ePageRank\u003c/em\u003e, \u003cem\u003eTriangle Counting\u003c/em\u003e…)\u003c/li\u003e\n  \u003cli\u003eSolo disponible en Scala\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDocumentación: \u003ca href\u003d\"http://spark.apache.org/docs/latest/graphx-programming-guide.html\"\u003ehttp://spark.apache.org/docs/latest/graphx-programming-guide.html\u003c/a\u003e\u003cbr/\u003eAPI: \u003ca href\u003d\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.graphx.package\"\u003ehttps://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.graphx.package\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508256538752_-1178381614",
      "id": "20170331-180728_888600905",
      "dateCreated": "2017-10-17 16:08:58.000",
      "dateStarted": "2018-11-09 11:13:06.000",
      "dateFinished": "2018-11-09 11:13:06.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## GraphFrames: procesamiento de grafos con DataFrames\nExtensión de GraphX basada en DataFrames\n\n- Esta desarrollandose para múltiples lenguages\n    - De momento, en Scala y Python \n- Todavía no incorporada en Spark\n    - Instalable a través de un paquete externo (https://spark-packages.org/package/graphframes/graphframes)\n\nMás información:\n- Web del proyecto: https://graphframes.github.io/graphframes/docs/_site/index.html\n- API Python: https://graphframes.github.io/graphframes/docs/_site/api/python/index.html\n- API Scala: https://graphframes.github.io/graphframes/docs/_site/api/scala/index.html#org.graphframes.package",
      "user": "anonymous",
      "dateUpdated": "2020-06-06 20:45:43.024",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eGraphFrames: procesamiento de grafos con DataFrames\u003c/h2\u003e\n\u003cp\u003eExtensión de GraphX basada en DataFrames\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eEsta desarrollandose para múltiples lenguages\n    \u003cul\u003e\n      \u003cli\u003eDe momento, en Scala y Python\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eTodavía no incorporada en Spark\n    \u003cul\u003e\n      \u003cli\u003eInstalable a través de un paquete externo (\u003ca href\u003d\"https://spark-packages.org/package/graphframes/graphframes\"\u003ehttps://spark-packages.org/package/graphframes/graphframes\u003c/a\u003e)\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eMás información:\u003cbr/\u003e- Web del proyecto: \u003ca href\u003d\"https://graphframes.github.io/graphframes/docs/_site/index.html\"\u003ehttps://graphframes.github.io/graphframes/docs/_site/index.html\u003c/a\u003e\u003cbr/\u003e- API Python: \u003ca href\u003d\"https://graphframes.github.io/graphframes/docs/_site/api/python/index.html\"\u003ehttps://graphframes.github.io/graphframes/docs/_site/api/python/index.html\u003c/a\u003e\u003cbr/\u003e- API Scala: \u003ca href\u003d\"https://graphframes.github.io/graphframes/docs/_site/api/scala/index.html#org.graphframes.package\"\u003ehttps://graphframes.github.io/graphframes/docs/_site/api/scala/index.html#org.graphframes.package\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1541761292323_1795012701",
      "id": "20181109-110132_1839013895",
      "dateCreated": "2018-11-09 11:01:32.000",
      "dateStarted": "2019-10-30 10:39:55.000",
      "dateFinished": "2019-10-30 10:39:55.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Grafos en GraphX\n\u003cimg src\u003d\"http://persoal.citius.usc.es/tf.pena/TCDM/figs/grapxgraph.png\" alt\u003d\"Grafo en GraphX\" style\u003d\"width: 600px;\"/\u003e\n(Fuente: M.S. Malak, R. East \"Spark GraphX in action\", Manning, 2016)",
      "user": "anonymous",
      "dateUpdated": "2020-06-06 20:45:43.024",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eGrafos en GraphX\u003c/h2\u003e\n\u003cimg src\u003d\"http://persoal.citius.usc.es/tf.pena/TCDM/figs/grapxgraph.png\" alt\u003d\"Grafo en GraphX\" style\u003d\"width: 600px;\"/\u003e\n\u003cp\u003e(Fuente: M.S. Malak, R. East \u0026ldquo;Spark GraphX in action\u0026rdquo;, Manning, 2016)\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508256538753_-1178766363",
      "id": "20170726-183141_1590092110",
      "dateCreated": "2017-10-17 16:08:58.000",
      "dateStarted": "2018-11-09 13:06:08.000",
      "dateFinished": "2018-11-09 13:06:08.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nEjemplo de grafo sencillo\n\u003cimg src\u003d\"http://persoal.citius.usc.es/tf.pena/TCDM/figs/simpsonsgraph.png\" alt\u003d\"Grafo de los Simpson\" style\u003d\"width: 600px;\"/\u003e\n(Fuente: P. Zecević, M. Bonaći \"Spark in action\", Manning, 2017)",
      "user": "anonymous",
      "dateUpdated": "2020-06-06 20:45:43.024",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eEjemplo de grafo sencillo\u003cbr/\u003e\u003cimg src\u003d\"http://persoal.citius.usc.es/tf.pena/TCDM/figs/simpsonsgraph.png\" alt\u003d\"Grafo de los Simpson\" style\u003d\"width: 600px;\"/\u003e\u003cbr/\u003e(Fuente: P. Zecević, M. Bonaći \u0026ldquo;Spark in action\u0026rdquo;, Manning, 2017)\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508256538753_-1178766363",
      "id": "20170726-183607_1221581747",
      "dateCreated": "2017-10-17 16:08:58.000",
      "dateStarted": "2017-10-17 16:31:16.000",
      "dateFinished": "2017-10-17 16:31:16.000",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\nimport org.apache.spark.graphx._\ncase class Person(name:String, age:Int)\nval vertices \u003d sc.parallelize(Array((1L, Person(\"Homer\", 39)),\n                                    (2L, Person(\"Marge\", 39)),\n                                    (3L, Person(\"Bart\", 12)),\n                                    (4L, Person(\"Milhouse\", 12))))\n                                    \nval aristas \u003d sc.parallelize(Array(Edge(4L, 3L, \"amigo\"),\n                                 Edge(3L, 1L, \"padre\"),\n                                 Edge(3L, 2L, \"madre\"),\n                                 Edge(1L, 2L, \"casadoCon\")))\n                                 \nval graph \u003d Graph(vertices, aristas)\n\nprintln(graph.vertices.count())\n\nprintln(graph.edges.count())",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:27:11.100",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "4\n4\nimport org.apache.spark.graphx._\ndefined class Person\nvertices: org.apache.spark.rdd.RDD[(Long, Person)] \u003d ParallelCollectionRDD[134] at parallelize at \u003cconsole\u003e:21\naristas: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[String]] \u003d ParallelCollectionRDD[135] at parallelize at \u003cconsole\u003e:26\ngraph: org.apache.spark.graphx.Graph[Person,String] \u003d org.apache.spark.graphx.impl.GraphImpl@6163f16e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508256538754_-1177612116",
      "id": "20170726-155609_1642557161",
      "dateCreated": "2017-10-17 16:08:58.000",
      "dateStarted": "2020-12-14 15:27:11.164",
      "dateFinished": "2020-12-14 15:27:11.835",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\nls /datos\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:29:32.246",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/sh"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "2015-summary.csv\nby-day\ncite75_99.txt\ndfSE2.parquet\ndfSE.json\ndfSE.parquet\nitalianPosts.csv.bz2\nquijote.txt\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1607959724471_10383853",
      "id": "20201214-152844_1718399168",
      "dateCreated": "2020-12-14 15:28:44.471",
      "dateStarted": "2020-12-14 15:29:32.263",
      "dateFinished": "2020-12-14 15:29:32.280",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n// Cramos un grafo a partir del fichero de citas\n// Tenemos que crear un RDD de tuplas de Longs\nval rdd \u003d sc.textFile(\"/datos/cite75_99.txt\").\n            filter(l \u003d\u003e !l.startsWith(\"\\\"CITING\\\"\")).\n            map(l \u003d\u003e {\n                val spl \u003d l.split(\",\");\n                (spl(0).toLong, spl(1).toLong)})\n                \nprintln(rdd.count())",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:30:00.247",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "16522438\nrdd: org.apache.spark.rdd.RDD[(Long, Long)] \u003d MapPartitionsRDD[165] at map at \u003cconsole\u003e:41\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508256538754_-1177612116",
      "id": "20170726-160230_323471961",
      "dateCreated": "2017-10-17 16:08:58.000",
      "dateStarted": "2020-12-14 15:30:00.271",
      "dateFinished": "2020-12-14 15:30:03.935",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n// Para que no tarde tanto, filtramos para reducir el tamaño del RDD\nval filtered \u003d rdd.\n                filter(p \u003d\u003e p._1 \u003e\u003d 3000000 \u0026\u0026 p._1 \u003c 4000000)\nprintln(filtered.count())\nfiltered.take(3)",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:30:10.158",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "679800\nfiltered: org.apache.spark.rdd.RDD[(Long, Long)] \u003d MapPartitionsRDD[166] at filter at \u003cconsole\u003e:41\nres11: Array[(Long, Long)] \u003d Array((3858241,956203), (3858241,1324234), (3858241,3398406))\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1541762297457_545634377",
      "id": "20181109-111817_293679040",
      "dateCreated": "2018-11-09 11:18:17.000",
      "dateStarted": "2020-12-14 15:30:10.176",
      "dateFinished": "2020-12-14 15:30:13.341",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n// Creamos el grafo\nval citeGraph \u003d Graph.fromEdgeTuples(filtered, 0)\n\nprintln(\"Número de vértices \u003d \"+citeGraph.numVertices)\nprintln(\"Número de aristas \u003d \"+citeGraph.numEdges)",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:31:08.753",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Número de vértices \u003d 585917\nNúmero de aristas \u003d 679800\nciteGraph: org.apache.spark.graphx.Graph[Int,Int] \u003d org.apache.spark.graphx.impl.GraphImpl@52332074\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508256538754_-1177612116",
      "id": "20170727-152614_1046212621",
      "dateCreated": "2017-10-17 16:08:58.000",
      "dateStarted": "2020-12-14 15:31:08.772",
      "dateFinished": "2020-12-14 15:31:13.411",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n// Usamos el algoritmo PageRank para obtener las patentes más populares\nval rank \u003d citeGraph.pageRank(0.1)\n\nval orden \u003d new Ordering[Tuple2[VertexId, Double]] {\n    def compare(x:Tuple2[VertexId, Double], y:Tuple2[VertexId, Double]):Int \u003d\n                x._2.compareTo(y._2)\n}\n\nval top10 \u003d rank.vertices.top(10)(orden)\n\nprintln(\"Patente con mayor rank \u003d \"+top10(0)._1+\" (rango \u003d \"+top10(0)._2+\")\")",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:31:58.326",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Patente con mayor rank \u003d 3706768 (rango \u003d 11.18942115355814)\nrank: org.apache.spark.graphx.Graph[Double,Double] \u003d org.apache.spark.graphx.impl.GraphImpl@3087d705\norden: Ordering[(org.apache.spark.graphx.VertexId, Double)] \u003d $anon$1@50762bb0\ntop10: Array[(org.apache.spark.graphx.VertexId, Double)] \u003d Array((3706768,11.18942115355814), (3763480,9.796659016812917), (3731986,9.545250708835361), (3708277,9.357174888913956), (2813048,8.760013717639591), (3165550,8.389095491916327), (3862984,8.271037028867836), (3697507,8.212007797343588), (3641021,7.776591831201632), (3382238,7.722908450428413))\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508256538754_-1177612116",
      "id": "20170727-155618_661977365",
      "dateCreated": "2017-10-17 16:08:58.000",
      "dateStarted": "2020-12-14 15:31:58.347",
      "dateFinished": "2020-12-14 15:32:03.860",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-05 17:37:58.013",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1544810297838_-927808123",
      "id": "20181214-175817_748553741",
      "dateCreated": "2018-12-14 17:58:17.000",
      "dateStarted": "2020-11-05 17:37:46.355",
      "dateFinished": "2020-11-05 17:37:46.514",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-05 17:37:46.341",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1604597866340_-518788362",
      "id": "20201105-173746_1786761383",
      "dateCreated": "2020-11-05 17:37:46.340",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Apache Spark/12 - Procesamiento de grafos",
  "id": "2CV9MN9EE",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "sh:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}