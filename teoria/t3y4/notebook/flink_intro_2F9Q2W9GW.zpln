{
  "paragraphs": [
    {
      "text": "%md\nIntroducción a [Apache Flink](http://flink.apache.org/)\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d",
      "user": "anonymous",
      "dateUpdated": "2020-04-24 16:20:34.889",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/text",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eIntroducción a \u003ca href\u003d\"http://flink.apache.org/\"\u003eApache Flink\u003c/a\u003e\u003c/h1\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1587743608285_-19218795",
      "id": "paragraph_1587580473446_2056226248",
      "dateCreated": "2020-04-24 15:53:28.285",
      "dateStarted": "2020-04-24 16:20:34.907",
      "dateFinished": "2020-04-24 16:20:34.917",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n---\n### Entorno y motor open-source de procesamiento distribuido\n\nOrientado a la computación sobre flujos de datos (streaming)\n\n- Flink distribuye las tareas en el cluster\n- Streaming puro (Spark usa \"microbatches\")\n- Operaciones con y sin estado (stateful/stateless)\n- Flujos limitados o ilimitados (unbounded/bounded)\n- Tolerancia a fallos mediante checkpoints periódicos\n- Garantía de entrega *exactly-once*\n    - Los eventos son procesados una y solo una vez\n  \nTambién permite procesamiento batch",
      "user": "anonymous",
      "dateUpdated": "2020-06-05 16:01:56.655",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 162.0,
              "optionOpen": false
            }
          }
        },
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003chr/\u003e\n\u003ch3\u003eEntorno y motor open-source de procesamiento distribuido\u003c/h3\u003e\n\u003cp\u003eOrientado a la computación sobre flujos de datos (streaming)\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eFlink distribuye las tareas en el cluster\u003c/li\u003e\n  \u003cli\u003eStreaming puro (Spark usa \u0026ldquo;microbatches\u0026rdquo;)\u003c/li\u003e\n  \u003cli\u003eOperaciones con y sin estado (stateful/stateless)\u003c/li\u003e\n  \u003cli\u003eFlujos limitados o ilimitados (unbounded/bounded)\u003c/li\u003e\n  \u003cli\u003eTolerancia a fallos mediante checkpoints periódicos\u003c/li\u003e\n  \u003cli\u003eGarantía de entrega \u003cem\u003eexactly-once\u003c/em\u003e\n    \u003cul\u003e\n      \u003cli\u003eLos eventos son procesados una y solo una vez\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTambién permite procesamiento batch\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1587743608287_7718102",
      "id": "paragraph_1587580642664_-1167715305",
      "dateCreated": "2020-04-24 15:53:28.287",
      "dateStarted": "2020-06-05 16:01:56.664",
      "dateFinished": "2020-06-05 16:01:56.702",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Historia\n- Iniciado en 2010 como el proyecto europeo [Stratosphere](http://stratosphere.eu/)\n    - Colaboración entre la [TU Berlin](https://www.tu-berlin.de), la [Humboldt-Universität](https://www.hu-berlin.de) y el [Hasso Plattner Institute](https://hpi.de/) (Alemania)\n-   Transferido a la Apache Software Foundation en marzo de 2014\n    - [Apache top-level project](https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces69) en enero de 2015\n- Versión 1.0 lanzada en marzo de 2016\n    - Versión más reciente: 1.12 (febrero 2020)\n- [Algunos usuarios](https://flink.apache.org/poweredby.html): Alibaba, AWS, ebay, Uber, Huawey, Xiaomi,...\n- Articulos relacionados\n    -  [The Stratosphere platform for big data analytics](https://link.springer.com/article/10.1007/s00778-014-0357-y)\n    -  [Apache Flink: Stream and Batch Processing in a Single Engine](http://www.diva-portal.org/smash/get/diva2:1059537/FULLTEXT01.pdf)\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:34:47.798",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eHistoria\u003c/h3\u003e\n\u003cul\u003e\n  \u003cli\u003eIniciado en 2010 como el proyecto europeo \u003ca href\u003d\"http://stratosphere.eu/\"\u003eStratosphere\u003c/a\u003e\n    \u003cul\u003e\n      \u003cli\u003eColaboración entre la \u003ca href\u003d\"https://www.tu-berlin.de\"\u003eTU Berlin\u003c/a\u003e, la \u003ca href\u003d\"https://www.hu-berlin.de\"\u003eHumboldt-Universität\u003c/a\u003e y el \u003ca href\u003d\"https://hpi.de/\"\u003eHasso Plattner Institute\u003c/a\u003e (Alemania)\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eTransferido a la Apache Software Foundation en marzo de 2014\n    \u003cul\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces69\"\u003eApache top-level project\u003c/a\u003e en enero de 2015\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eVersión 1.0 lanzada en marzo de 2016\n    \u003cul\u003e\n      \u003cli\u003eVersión más reciente: 1.12 (febrero 2020)\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://flink.apache.org/poweredby.html\"\u003eAlgunos usuarios\u003c/a\u003e: Alibaba, AWS, ebay, Uber, Huawey, Xiaomi,\u0026hellip;\u003c/li\u003e\n  \u003cli\u003eArticulos relacionados\n    \u003cul\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://link.springer.com/article/10.1007/s00778-014-0357-y\"\u003eThe Stratosphere platform for big data analytics\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"http://www.diva-portal.org/smash/get/diva2:1059537/FULLTEXT01.pdf\"\u003eApache Flink: Stream and Batch Processing in a Single Engine\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1587743608288_734965229",
      "id": "paragraph_1587580809876_-145430207",
      "dateCreated": "2020-04-24 15:53:28.288",
      "dateStarted": "2020-12-14 15:34:47.799",
      "dateFinished": "2020-12-14 15:34:47.822",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Modelo Flink\n---\n![Modelo Flink](http://persoal.citius.usc.es/tf.pena/TCDM/figs/flink-home-graphic.png)\n---\n\n- Event-driven applications: ejecutan acciones como respuesta a eventos\n\n    - Recomendadores en tiempo real\n    - Detección de patrones o anomalías\n\n-  Streaming pipelines: ingesta, validación, combinación, transformación e inserción de datos con baja latencia\n\n    - Recogida de datos de múltiples fuentes\n    - Trasvase de datos a la nube\n    \n- Stream analytics: análisis de datos a medida que se reciben\n\n    - Análisis del comportamiento de usuarios en aplicaciones móviles\n    - Monitorización de la calidad de redes",
      "user": "anonymous",
      "dateUpdated": "2020-05-19 15:46:59.299",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eModelo Flink\u003c/h3\u003e\n\u003chr/\u003e\n\u003ch2\u003e\u003cimg src\u003d\"http://persoal.citius.usc.es/tf.pena/TCDM/figs/flink-home-graphic.png\" alt\u003d\"Modelo Flink\" /\u003e\u003c/h2\u003e\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eEvent-driven applications: ejecutan acciones como respuesta a eventos\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eRecomendadores en tiempo real\u003c/li\u003e\n      \u003cli\u003eDetección de patrones o anomalías\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eStreaming pipelines: ingesta, validación, combinación, transformación e inserción de datos con baja latencia\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eRecogida de datos de múltiples fuentes\u003c/li\u003e\n      \u003cli\u003eTrasvase de datos a la nube\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eStream analytics: análisis de datos a medida que se reciben\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eAnálisis del comportamiento de usuarios en aplicaciones móviles\u003c/li\u003e\n      \u003cli\u003eMonitorización de la calidad de redes\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1587743608289_-885373557",
      "id": "paragraph_1587662567346_-105332130",
      "dateCreated": "2020-04-24 15:53:28.289",
      "dateStarted": "2020-05-19 15:46:59.309",
      "dateFinished": "2020-05-19 15:46:59.399",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Características\n- Procesamiento *in-memory* y ejecución *lazy*\n    - Rendimiento similar al de Spark\n- Integrado con gestores de recursos como YARN, Mesos y Kubernetes (también modo standalone)\n- Programable en [Scala](https://ci.apache.org/projects/flink/flink-docs-release-1.10/api/scala/index.html#org.apache.flink.api.scala.package) y [Java](https://ci.apache.org/projects/flink/flink-docs-release-1.10/api/java/)\n    - Versión para [Python](https://ci.apache.org/projects/flink/flink-docs-release-1.10/api/python/) ([PyFlink](https://www.alibabacloud.com/blog/use-python-api-in-apache-flink_595680)) en desarrollo\n- Dos APIs\n    - [DataStream API](https://ci.apache.org/projects/flink/flink-docs-stable/dev/datastream_api.html): procesamiento de flujos\n    - [DataSet API](https://ci.apache.org/projects/flink/flink-docs-stable/dev/batch/index.html): procesamiento batch\n- Otras extensiones\n    - [Table API y SQL](https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/): consultas tipo SQL para flujos y batch \n    - [FlinkCEP](https://ci.apache.org/projects/flink/flink-docs-stable/dev/libs/cep.html): Procesamiento de enventos complejos en Flink ([*Complex event processing*](https://en.wikipedia.org/wiki/Complex_event_processing))\n    - [Gelly](https://ci.apache.org/projects/flink/flink-docs-stable/dev/libs/gelly/): API para el procesamiento de grafos\n    - [FlinkML](https://cwiki.apache.org/confluence/display/FLINK/FLIP-39+Flink+ML+pipeline+and+ML+libs): Machine Learning sobre Flink (en desarrollo para TableAPI)",
      "user": "anonymous",
      "dateUpdated": "2020-04-28 17:05:55.795",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eCaracterísticas\u003c/h3\u003e\n\u003cul\u003e\n  \u003cli\u003eProcesamiento \u003cem\u003ein-memory\u003c/em\u003e y ejecución \u003cem\u003elazy\u003c/em\u003e\n    \u003cul\u003e\n      \u003cli\u003eRendimiento similar al de Spark\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eIntegrado con gestores de recursos como YARN, Mesos y Kubernetes (también modo standalone)\u003c/li\u003e\n  \u003cli\u003eProgramable en \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-release-1.10/api/scala/index.html#org.apache.flink.api.scala.package\"\u003eScala\u003c/a\u003e y \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-release-1.10/api/java/\"\u003eJava\u003c/a\u003e\n    \u003cul\u003e\n      \u003cli\u003eVersión para \u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-release-1.10/api/python/\"\u003ePython\u003c/a\u003e (\u003ca href\u003d\"https://www.alibabacloud.com/blog/use-python-api-in-apache-flink_595680\"\u003ePyFlink\u003c/a\u003e) en desarrollo\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eDos APIs\n    \u003cul\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/datastream_api.html\"\u003eDataStream API\u003c/a\u003e: procesamiento de flujos\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/batch/index.html\"\u003eDataSet API\u003c/a\u003e: procesamiento batch\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eOtras extensiones\n    \u003cul\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/\"\u003eTable API y SQL\u003c/a\u003e: consultas tipo SQL para flujos y batch\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/libs/cep.html\"\u003eFlinkCEP\u003c/a\u003e: Procesamiento de enventos complejos en Flink (\u003ca href\u003d\"https://en.wikipedia.org/wiki/Complex_event_processing\"\u003e\u003cem\u003eComplex event processing\u003c/em\u003e\u003c/a\u003e)\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/libs/gelly/\"\u003eGelly\u003c/a\u003e: API para el procesamiento de grafos\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://cwiki.apache.org/confluence/display/FLINK/FLIP-39+Flink+ML+pipeline+and+ML+libs\"\u003eFlinkML\u003c/a\u003e: Machine Learning sobre Flink (en desarrollo para TableAPI)\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1587743608290_-1522734959",
      "id": "paragraph_1587582992009_48650020",
      "dateCreated": "2020-04-24 15:53:28.290",
      "dateStarted": "2020-04-28 17:05:55.794",
      "dateFinished": "2020-04-28 17:05:55.887",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Ecosistema Flink\n---\n![Ecosistema Flink](http://persoal.citius.usc.es/tf.pena/TCDM/figs/Ecosistema_Flink.png)\n---",
      "user": "anonymous",
      "dateUpdated": "2020-04-28 16:56:20.837",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEcosistema Flink\u003c/h3\u003e\n\u003chr/\u003e\n\u003ch2\u003e\u003cimg src\u003d\"http://persoal.citius.usc.es/tf.pena/TCDM/figs/Ecosistema_Flink.png\" alt\u003d\"Ecosistema Flink\" /\u003e\u003c/h2\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1588092925759_-17297028",
      "id": "20200428-165525_863751230",
      "dateCreated": "2020-04-28 16:55:25.759",
      "dateStarted": "2020-04-28 16:56:20.862",
      "dateFinished": "2020-04-28 16:56:20.885",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Fuentes y destinos de datos\nFlink permite obtener su entrada de diferentes fuentes ( *data sources* ) y enviar la salida a diferentes destinos ( *data sinks* )\n\n- [Sistemas de ficheros](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/filesystems/index.html)\n    - Sistemas de ficheros local\n    - Todos los soportados por Hadoop ([Hadoop-compatible file systems](https://cwiki.apache.org/confluence/display/HADOOP2/HCFS))\n    - [Amazon S3](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/filesystems/s3.html)\n    - [Aliyun Object Storage Service (OSS)](https://ci.apache.org/projects/flink/flink-docs-master/deployment/filesystems/oss.html)\n    - [Azure Blob Storage](https://ci.apache.org/projects/flink/flink-docs-master/deployment/filesystems/azure.html)\n- Conexiones a sockets\n- Colecciones Java\n- [Conectores streaming](https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/)\n    - [Streaming File Sink](https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/streamfile_sink.html) (sink)\n    - [Apache Kafka](https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/kafka.html) (source/sink)\n    - [Apache Cassandra](https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/cassandra.html) (sink)\n    - [Amazon Kinesis Streams](https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/kinesis.html) (source/sink)\n    - [Elasticsearch](https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/elasticsearch.html) (sink)\n    - [RabbitMQ](https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/rabbitmq.html) (source/sink)\n    - [Apache NiFi](https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/nifi.html) (source/sink)\n    - [Twitter Streaming API](https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/twitter.html) (source)\n    - [Google Cloud PubSub](https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/pubsub.html) (source/sink)\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 12:26:12.680",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eFuentes y destinos de datos\u003c/h3\u003e\n\u003cp\u003eFlink permite obtener su entrada de diferentes fuentes ( \u003cem\u003edata sources\u003c/em\u003e ) y enviar la salida a diferentes destinos ( \u003cem\u003edata sinks\u003c/em\u003e )\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/filesystems/index.html\"\u003eSistemas de ficheros\u003c/a\u003e\n    \u003cul\u003e\n      \u003cli\u003eSistemas de ficheros local\u003c/li\u003e\n      \u003cli\u003eTodos los soportados por Hadoop (\u003ca href\u003d\"https://cwiki.apache.org/confluence/display/HADOOP2/HCFS\"\u003eHadoop-compatible file systems\u003c/a\u003e)\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/filesystems/s3.html\"\u003eAmazon S3\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-master/deployment/filesystems/oss.html\"\u003eAliyun Object Storage Service (OSS)\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-master/deployment/filesystems/azure.html\"\u003eAzure Blob Storage\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eConexiones a sockets\u003c/li\u003e\n  \u003cli\u003eColecciones Java\u003c/li\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/\"\u003eConectores streaming\u003c/a\u003e\n    \u003cul\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/streamfile_sink.html\"\u003eStreaming File Sink\u003c/a\u003e (sink)\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/kafka.html\"\u003eApache Kafka\u003c/a\u003e (source/sink)\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/cassandra.html\"\u003eApache Cassandra\u003c/a\u003e (sink)\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/kinesis.html\"\u003eAmazon Kinesis Streams\u003c/a\u003e (source/sink)\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/elasticsearch.html\"\u003eElasticsearch\u003c/a\u003e (sink)\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/rabbitmq.html\"\u003eRabbitMQ\u003c/a\u003e (source/sink)\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/nifi.html\"\u003eApache NiFi\u003c/a\u003e (source/sink)\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/twitter.html\"\u003eTwitter Streaming API\u003c/a\u003e (source)\u003c/li\u003e\n      \u003cli\u003e\u003ca href\u003d\"https://ci.apache.org/projects/flink/flink-docs-stable/dev/connectors/pubsub.html\"\u003eGoogle Cloud PubSub\u003c/a\u003e (source/sink)\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1587743608291_-1894909505",
      "id": "paragraph_1587662459928_1280429211",
      "dateCreated": "2020-04-24 15:53:28.291",
      "dateStarted": "2020-12-14 12:26:12.681",
      "dateFinished": "2020-12-14 12:26:12.707",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Componentes de Flink\n---\n![Modelo Flink](http://persoal.citius.usc.es/tf.pena/TCDM/figs/Application_submission.png)\n---\n\n- **JobManager**: controla la ejecución de una aplicación\n    - Cada aplicación es controlada por un JobManager\n    - Aplicación: grafo de tareas ( *JobGraph* )\n    - El JobManager lo convierte en un grafo de ejecución ( *ExecutionGraph* )\n    - Conjunto de tareas que pueden ejecutarse en paralelo\n    - El JobManager pide recursos ( *TaskManager slots* ) al ResorceManager\n    - Durante la ejecución se encarga de la coordinación central (p.e. *checkpoints*)\n    - Fallos en el JobManager se gestionan usando checkpoints y [Apache Zookeeper](https://zookeeper.apache.org/)\n- **ResourceManager**: Inicia y gestiona los TaskManager \n    - Diferentes versiones para diferentes gestores de cluster: YARN, Mesos, Kubernetes, standalone\n    - Solicita recursos a los gestores e inicia procesos TaskManager\n    - Libera los TaskManager cuando han finalizado\n- **TaskManagers**: ejecutan tareas en paralelo\n    - Cada TaskManager ofrece un número de slots al JobManager, bajo petición del ResourceManager\n    - El JobManager le envía tareas para su ejecución\n- **Dispatcher**: proporciona una interfaz REST para enviar aplicaciones\n    - También ejecuta el interfaz web de Flink",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 12:36:43.747",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eComponentes de Flink\u003c/h3\u003e\n\u003chr/\u003e\n\u003ch2\u003e\u003cimg src\u003d\"http://persoal.citius.usc.es/tf.pena/TCDM/figs/Application_submission.png\" alt\u003d\"Modelo Flink\" /\u003e\u003c/h2\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003cstrong\u003eJobManager\u003c/strong\u003e: controla la ejecución de una aplicación\n    \u003cul\u003e\n      \u003cli\u003eCada aplicación es controlada por un JobManager\u003c/li\u003e\n      \u003cli\u003eAplicación: grafo de tareas ( \u003cem\u003eJobGraph\u003c/em\u003e )\u003c/li\u003e\n      \u003cli\u003eEl JobManager lo convierte en un grafo de ejecución ( \u003cem\u003eExecutionGraph\u003c/em\u003e )\u003c/li\u003e\n      \u003cli\u003eConjunto de tareas que pueden ejecutarse en paralelo\u003c/li\u003e\n      \u003cli\u003eEl JobManager pide recursos ( \u003cem\u003eTaskManager slots\u003c/em\u003e ) al ResorceManager\u003c/li\u003e\n      \u003cli\u003eDurante la ejecución se encarga de la coordinación central (p.e. \u003cem\u003echeckpoints\u003c/em\u003e)\u003c/li\u003e\n      \u003cli\u003eFallos en el JobManager se gestionan usando checkpoints y \u003ca href\u003d\"https://zookeeper.apache.org/\"\u003eApache Zookeeper\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003eResourceManager\u003c/strong\u003e: Inicia y gestiona los TaskManager\n    \u003cul\u003e\n      \u003cli\u003eDiferentes versiones para diferentes gestores de cluster: YARN, Mesos, Kubernetes, standalone\u003c/li\u003e\n      \u003cli\u003eSolicita recursos a los gestores e inicia procesos TaskManager\u003c/li\u003e\n      \u003cli\u003eLibera los TaskManager cuando han finalizado\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003eTaskManagers\u003c/strong\u003e: ejecutan tareas en paralelo\n    \u003cul\u003e\n      \u003cli\u003eCada TaskManager ofrece un número de slots al JobManager, bajo petición del ResourceManager\u003c/li\u003e\n      \u003cli\u003eEl JobManager le envía tareas para su ejecución\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003eDispatcher\u003c/strong\u003e: proporciona una interfaz REST para enviar aplicaciones\n    \u003cul\u003e\n      \u003cli\u003eTambién ejecuta el interfaz web de Flink\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1587743608293_1553216553",
      "id": "paragraph_1587665381668_1431787726",
      "dateCreated": "2020-04-24 15:53:28.293",
      "dateStarted": "2020-12-14 12:36:43.751",
      "dateFinished": "2020-12-14 12:36:43.772",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Entorno de ejecución\n- El entorno de ejecución ( *execution environment* ) determina la forma en que se ejecutará la aplicación\n    - Ejecución en local o cluster\n- Para obtener el entorno por defecto para el DataStream API\n\n        import org.apache.flink.streaming.api.scala._\n        ....\n            val env \u003d StreamExecutionEnvironment.getExecutionEnvironment\n            \n- Para el DataSet API\n\n        import org.apache.flink.api.scala._\n        ....\n            val env \u003d ExecutionEnvironment.getExecutionEnvironment\n            \n- Dentro del Zeppelin, están predefinidos en las variables **senv** y **benv**",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 12:37:46.786",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEntorno de ejecución\u003c/h3\u003e\n\u003cul\u003e\n  \u003cli\u003eEl entorno de ejecución ( \u003cem\u003eexecution environment\u003c/em\u003e ) determina la forma en que se ejecutará la aplicación\n    \u003cul\u003e\n      \u003cli\u003eEjecución en local o cluster\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003ePara obtener el entorno por defecto para el DataStream API\n    \u003cpre\u003e\u003ccode\u003eimport org.apache.flink.streaming.api.scala._\n....\n    val env \u003d StreamExecutionEnvironment.getExecutionEnvironment\n\u003c/code\u003e\u003c/pre\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003ePara el DataSet API\u003c/p\u003e\n    \u003cpre\u003e\u003ccode\u003eimport org.apache.flink.api.scala._\n....\n    val env \u003d ExecutionEnvironment.getExecutionEnvironment\n\u003c/code\u003e\u003c/pre\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eDentro del Zeppelin, están predefinidos en las variables \u003cstrong\u003esenv\u003c/strong\u003e y \u003cstrong\u003ebenv\u003c/strong\u003e\u003c/p\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1587743608297_-36088720",
      "id": "paragraph_1587671297678_203657121",
      "dateCreated": "2020-04-24 15:53:28.297",
      "dateStarted": "2020-12-14 12:37:46.786",
      "dateFinished": "2020-12-14 12:37:46.794",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n",
      "user": "anonymous",
      "dateUpdated": "2020-04-24 15:57:16.654",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1587743836648_-440855126",
      "id": "20200424-155716_1004885159",
      "dateCreated": "2020-04-24 15:57:16.648",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Introducción a Apache Flink/Apache Flink",
  "id": "2F9Q2W9GW",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "sh:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}