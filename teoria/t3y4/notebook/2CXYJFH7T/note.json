{
  "paragraphs": [
    {
      "text": "%md\n## Spark MLlib: Machine Learning Library\n\nLibrería de algoritmos paralelos de ML para datos masivos\n\n-   Algoritmos clásicos de machine learning: clasificación, regresión, clustering, filtrado colaborativo\n-   Otros algoritmos: extracción de características, transformación, reducción de dimensionalidad y selección\n-   Herramientas para construir, evaluar y ajustar pipelines de ML\n-   Otras utilidades: álgebra lineal, estadística, manejo de datos, etc.\n\n\nDos paquetes:\n\n-   spark.mllib: API original, basada en RDDs\n    - En *mantenimiento*  \n-   spark.ml: API de alto nivel, basada en DataFrames\n\nDocumentación y APIS:\n\n- ML\n    - Guia: http://spark.apache.org/docs/latest/ml-guide.html\n    - API Python: https://spark.apache.org/docs/latest/api/python/pyspark.ml.html\n    - API Scala: https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.package\n- MLlib\n    - Guia: http://spark.apache.org/docs/latest/mllib-guide.html\n    - API Python: https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html\n    - API Scala: https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.package\n",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:20:57.270",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eSpark MLlib: Machine Learning Library\u003c/h2\u003e\n\u003cp\u003eLibrería de algoritmos paralelos de ML para datos masivos\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eAlgoritmos clásicos de machine learning: clasificación, regresión, clustering, filtrado colaborativo\u003c/li\u003e\n  \u003cli\u003eOtros algoritmos: extracción de características, transformación, reducción de dimensionalidad y selección\u003c/li\u003e\n  \u003cli\u003eHerramientas para construir, evaluar y ajustar pipelines de ML\u003c/li\u003e\n  \u003cli\u003eOtras utilidades: álgebra lineal, estadística, manejo de datos, etc.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDos paquetes:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003espark.mllib: API original, basada en RDDs\n    \u003cul\u003e\n      \u003cli\u003eEn \u003cem\u003emantenimiento\u003c/em\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003espark.ml: API de alto nivel, basada en DataFrames\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDocumentación y APIS:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eML\n    \u003cul\u003e\n      \u003cli\u003eGuia: \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-guide.html\"\u003ehttp://spark.apache.org/docs/latest/ml-guide.html\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003eAPI Python: \u003ca href\u003d\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html\"\u003ehttps://spark.apache.org/docs/latest/api/python/pyspark.ml.html\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003eAPI Scala: \u003ca href\u003d\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.package\"\u003ehttps://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.package\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eMLlib\n    \u003cul\u003e\n      \u003cli\u003eGuia: \u003ca href\u003d\"http://spark.apache.org/docs/latest/mllib-guide.html\"\u003ehttp://spark.apache.org/docs/latest/mllib-guide.html\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003eAPI Python: \u003ca href\u003d\"https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html\"\u003ehttps://spark.apache.org/docs/latest/api/python/pyspark.mllib.html\u003c/a\u003e\u003c/li\u003e\n      \u003cli\u003eAPI Scala: \u003ca href\u003d\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.package\"\u003ehttps://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.package\u003c/a\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508256507160_-831920425",
      "id": "20170331-180617_750285813",
      "dateCreated": "2017-10-17 16:08:27.000",
      "dateStarted": "2020-12-14 15:20:57.275",
      "dateFinished": "2020-12-14 15:20:59.742",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Ejemplo\n\nUsa el algoritmo de clustering [KMeans](http://spark.apache.org/docs/latest/mllib-clustering.html#k-means) para agrupar datos de vectores dispersos en dos clusters.\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-07 10:55:21.170",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eEjemplo\u003c/h4\u003e\n\u003cp\u003eUsa el algoritmo de clustering \u003ca href\u003d\"http://spark.apache.org/docs/latest/mllib-clustering.html#k-means\"\u003eKMeans\u003c/a\u003e para agrupar datos de vectores dispersos en dos clusters.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508256507164_-833459421",
      "id": "20170727-102127_29698974",
      "dateCreated": "2017-10-17 16:08:27.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nfrom pyspark.ml.clustering import KMeans, KMeansModel\nfrom pyspark.ml.linalg import Vectors\n\n# Define un array de 4 vectores dispersos, de 3 elementos cada uno\nsparseData \u003d [\n     Vectors.sparse(3, {1: 1.2}),\n     Vectors.sparse(3, {1: 1.1}),\n     Vectors.sparse(3, {0: 0.9, 2: 1.0}),\n     Vectors.sparse(3, {0: 1.0, 2: 1.1})\n ]\n\nfor i in range(4):\n    print(sparseData[i].toArray())",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:14:36.382",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[ 0.   1.2  0. ]\n[ 0.   1.1  0. ]\n[ 0.9  0.   1. ]\n[ 1.   0.   1.1]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1541752166128_1981935844",
      "id": "20181109-082926_660373199",
      "dateCreated": "2018-11-09 08:29:26.000",
      "dateStarted": "2020-12-14 15:14:36.532",
      "dateFinished": "2020-12-14 15:14:54.628",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Convierte el array en un DataFrame\ndfSD \u003d sc.parallelize([\n  (1, sparseData[0]),\n  (2, sparseData[1]),\n  (3, sparseData[2]),\n  (4, sparseData[3])\n]).toDF([\"fila\", \"caracteristicas\"])\n\ndfSD.show()",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:15:24.461",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----+-------------------+\n|fila|    caracteristicas|\n+----+-------------------+\n|   1|      (3,[1],[1.2])|\n|   2|      (3,[1],[1.1])|\n|   3|(3,[0,2],[0.9,1.0])|\n|   4|(3,[0,2],[1.0,1.1])|\n+----+-------------------+\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1541755536901_-529902578",
      "id": "20181109-092536_1184536681",
      "dateCreated": "2018-11-09 09:25:36.000",
      "dateStarted": "2020-12-14 15:15:24.527",
      "dateFinished": "2020-12-14 15:15:27.683",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Creamos un modelo KMeans sin entrenar, con 2 clusters\n# para más opciones ver https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.clustering\nkmeans \u003d KMeans()\\\n    .setInitMode(\"k-means||\")\\\n    .setFeaturesCol(\"caracteristicas\")\\\n    .setPredictionCol(\"prediccion\")\\\n    .setK(2)\\\n    .setSeed(1)",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:17:16.985",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1541752874490_855674198",
      "id": "20181109-084114_951001415",
      "dateCreated": "2018-11-09 08:41:14.000",
      "dateStarted": "2020-12-14 15:17:17.044",
      "dateFinished": "2020-12-14 15:17:17.147",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Ajustamos el modelo al DataFrame anterior y mostramos los centros de los clusters\nkmModel \u003d kmeans.fit(dfSD)\nprint(\"Centros de los clusters: {0}\".format(\n    kmModel.clusterCenters()))",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:17:41.005",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Centros de los clusters: [array([ 0.95,  0.  ,  1.05]), array([ 0.  ,  1.15,  0.  ])]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1541752958350_1762257185",
      "id": "20181109-084238_1003956342",
      "dateCreated": "2018-11-09 08:42:38.000",
      "dateStarted": "2020-12-14 15:17:41.055",
      "dateFinished": "2020-12-14 15:17:43.666",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Vemos como el modelo clusteriza los datos del array anterior\nkmModel.transform(dfSD).show()\n# Cálcula el coste como la suma de la distancia al cuadrado entre los puntos de entrada\n# y los centros de los clusters correspondientes\nprint(\"Coste \u003d {0}\".format(\n    kmModel.computeCost(dfSD)))",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:18:02.720",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----+-------------------+----------+\n|fila|    caracteristicas|prediccion|\n+----+-------------------+----------+\n|   1|      (3,[1],[1.2])|         1|\n|   2|      (3,[1],[1.1])|         1|\n|   3|(3,[0,2],[0.9,1.0])|         0|\n|   4|(3,[0,2],[1.0,1.1])|         0|\n+----+-------------------+----------+\n\nCoste \u003d 0.015\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1541755633182_-762692892",
      "id": "20181109-092713_312543758",
      "dateCreated": "2018-11-09 09:27:13.000",
      "dateStarted": "2020-12-14 15:18:02.763",
      "dateFinished": "2020-12-14 15:18:03.337",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Probamos el modelo con otros puntos\ndfTest \u003d sc.parallelize([\n  (1, Vectors.sparse(3, {0: 0.9, 1:1.0, 2: 1.0})),\n  (2, Vectors.sparse(3, {1: 1.5, 2: 0.3}))\n]).toDF([\"fila\", \"caracteristicas\"])\n\nkmModel.transform(dfTest).show(truncate\u003dFalse)\n\n# Cálcula el coste como la suma de la distancia al cuadrado entre los puntos de entrada\n# y los centros de los clusters correspondientes\nprint(\"Coste \u003d {0}\".format(\n    kmModel.computeCost(dfTest)))",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:19:38.226",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----+-------------------------+----------+\n|fila|caracteristicas          |prediccion|\n+----+-------------------------+----------+\n|1   |(3,[0,1,2],[0.9,1.0,1.0])|0         |\n|2   |(3,[1,2],[1.5,0.3])      |1         |\n+----+-------------------------+----------+\n\nCoste \u003d 1.2175\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1541753986677_1970630046",
      "id": "20181109-085946_1388911311",
      "dateCreated": "2018-11-09 08:59:46.000",
      "dateStarted": "2020-12-14 15:19:38.270",
      "dateFinished": "2020-12-14 15:19:39.224",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Salva el modelo en un directorio\nkmModel.save(\"/tmp/kmModel\")",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:20:15.864",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1508256507165_-833844169",
      "id": "20170726-155222_438709283",
      "dateCreated": "2017-10-17 16:08:27.000",
      "dateStarted": "2020-12-14 15:20:15.900",
      "dateFinished": "2020-12-14 15:20:16.881",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n# Vuelve a cargar el modelo\nsameModel \u003d KMeansModel.load(\"/tmp/kmModel\")\n\nsameModel.transform(dfTest).show(truncate\u003dFalse)\n# Cálcula el coste como la suma de la distancia al cuadrado entre los puntos de entrada\n# y los centros de los clusters correspondientes\nprint(\"Coste \u003d {0}\".format(\n    sameModel.computeCost(dfTest)))",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:20:26.499",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----+-------------------------+----------+\n|fila|caracteristicas          |prediccion|\n+----+-------------------------+----------+\n|1   |(3,[0,1,2],[0.9,1.0,1.0])|0         |\n|2   |(3,[1,2],[1.5,0.3])      |1         |\n+----+-------------------------+----------+\n\nCoste \u003d 1.2175\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1541757562506_-1682124795",
      "id": "20181109-095922_689922459",
      "dateCreated": "2018-11-09 09:59:22.000",
      "dateStarted": "2020-12-14 15:20:26.531",
      "dateFinished": "2020-12-14 15:20:27.712",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\nls -l /tmp/kmModel/data\nrm -rf /tmp/kmModel",
      "user": "anonymous",
      "dateUpdated": "2020-12-14 15:20:34.555",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "total 4\n-rw-r--r-- 1 root root 1609 Dec 14 15:20 part-00000-94c250bd-4537-4f5f-acb3-5d5e19bdcfd4-c000.snappy.parquet\n-rw-r--r-- 1 root root    0 Dec 14 15:20 _SUCCESS\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508256507165_-833844169",
      "id": "20170726-155249_436785497",
      "dateCreated": "2017-10-17 16:08:27.000",
      "dateStarted": "2020-12-14 15:20:34.586",
      "dateFinished": "2020-12-14 15:20:36.742",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-05 17:36:49.184",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1545245701254_1666777948",
      "id": "20181219-185501_925080628",
      "dateCreated": "2018-12-19 18:55:01.000",
      "dateStarted": "2020-11-05 17:36:36.571",
      "dateFinished": "2020-11-05 17:36:36.604",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2020-11-05 17:36:36.557",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1604597796553_-878624169",
      "id": "20201105-173636_2140869285",
      "dateCreated": "2020-11-05 17:36:36.553",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Apache Spark/11 - Spark MLlib",
  "id": "2CXYJFH7T",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "sh:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}