{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be55dcad-878d-4f75-841e-7d7ef83c591a",
   "metadata": {},
   "source": [
    "# Notas a la realización de la práctica\n",
    "\n",
    "Este documento ofrece algunas indicaciones para la realización de la práctica, que podéis tener en cuenta para evitar errores y para saber cómo recuperar en ciertas situaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9deab44-e592-49be-b73e-3fa8fecdffff",
   "metadata": {},
   "source": [
    "## Docker, imágenes y contenedores\n",
    "\n",
    "Docker permite tener imágenes de pequeñas máquinas virtuales. Estas imágenes son conjuntos de ficheros \"inertes\" que se pueden utilizar como base para lanzar **contenedores**. Los contenedores ejecutan los ficheros de una imagen para tener una instancia en ejecución (contenedor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc3689e-a3aa-4862-b05d-8828857000ee",
   "metadata": {},
   "source": [
    "Para saber las imágenes de las que disponemos, podemos hacer `docker images`:\n",
    "\n",
    "```bash\n",
    "$ docker images\n",
    "REPOSITORY               TAG       IMAGE ID       CREATED        SIZE\n",
    "backupnode-image         latest    ea8e71ca5aee   2 weeks ago    2.18GB\n",
    "namenode-image           latest    e39efb460f05   2 weeks ago    2.18GB\n",
    "datanode-image           latest    9f3e878eea85   2 weeks ago    2.18GB\n",
    "hadoop-base              latest    67efd4a138e9   2 weeks ago    2.06GB\n",
    "```\n",
    "\n",
    "Esto muestra las distintas imágenes, su tamaño y cuándo se crearon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b05ec-4c8b-4238-bfaf-d9f91709b882",
   "metadata": {},
   "source": [
    "Por otro lado, los contenedores en ejecución se pueden comprobar con `docker ps`. Algunos contenedores estarán en ejecución y otros parados. Si queremos ver todos los contenedores que se ejecutaron en algún momento y que no han sido eliminados, podemos hacer `docker ps -a`:\n",
    "\n",
    "```bash\n",
    "$ docker ps -a\n",
    "CONTAINER ID   IMAGE                    COMMAND                  CREATED       STATUS                     PORTS                    NAMES\n",
    "e18adb742526   jupyter/scipy-notebook   \"tini -g -- start-no…\"   4 days ago    Up 5 minutes               0.0.0.0:8888->8888/tcp   practicas-notebook-1\n",
    "c090609eead9   hadoop-base              \"/bin/bash\"              2 weeks ago   Exited (0) 4 days ago                               timelineserver\n",
    "f9436f4c87d9   backupnode-image         \"su hdadmin -c 'JAVA…\"   2 weeks ago   Exited (143) 4 days ago                             backupnode\n",
    "f8f93fd2a451   datanode-image           \"/inicio.sh\"             2 weeks ago   Exited (137) 4 days ago                             datanode4\n",
    "3d75f2614562   datanode-image           \"/inicio.sh\"             2 weeks ago   Exited (137) 4 days ago                             datanode1\n",
    "243ba043e9e7   namenode-image           \"/inicio.sh\"             2 weeks ago   Exited (137) 4 days ago                             namenode\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb01c1f-7438-42e7-852b-107138b8811c",
   "metadata": {},
   "source": [
    "A veces un contenedor no funciona como debería, o hemos cometido un error. Para continuar con la práctica, lo más sencillo es eliminarlo (pararlo primero si no está parado con `docker stop contenedor`) con `docker rm contenedor`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d98eb-4ff1-42bd-9271-7420b2c32144",
   "metadata": {},
   "source": [
    "Si por el contrario el contenedor está correctamente creado, podemos ponerlo a ejecutar como se especifica en la práctica. En este caso se lanzan a la vez el namenode y los cuatro datanodes:\n",
    "\n",
    "```bash\n",
    "docker start namenode datanode{1..4}\n",
    "```\n",
    "\n",
    "Al hacer `start`, los servicios del nodo comienzan a ejecutarse de nuevo, y si todos los nodos se ejecutan más o menos al mismo tiempo, la infraestructura de Hadoop hace que se empiecen a ver unos a otros y se pueda utilizar el clúster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6951401-ccdd-456f-9c73-279c3a609e8c",
   "metadata": {},
   "source": [
    "## Servicios dentro de un contenedor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed2de8-1af3-47b7-b816-6d0eb50685e3",
   "metadata": {},
   "source": [
    "Una vez un contenedor se ha iniciado (con `start` como arriba), se puede \"entrar dentro\" haciendo uso de la construcción `docker exec` y ejecutando el *shell* de Linux, el bash, teniendo en cuenta pasarle los parámetros `-ti` para que el contenedor mantenga una terminal abierta y podamos interactuar con él:\n",
    "\n",
    "```bash\n",
    "$ docker exec -ti namenode bash\n",
    "```\n",
    "\n",
    "El contenedor nos mostrará un *prompt* que nos indicará que estamos dentro:\n",
    "\n",
    "```bash\n",
    "root@namenode:~# \n",
    "```\n",
    "\n",
    "Nótese que el contenedor se establece en el superusuario por defecto (`root`), y en algún momento deberemos pasar al usuario `hdadmin`:\n",
    "\n",
    "```bash\n",
    "# su - hdadmin\n",
    "```\n",
    "\n",
    "(el \"`-`\" se utiliza para que el sistema operativo lea el fichero `~/.bashrc`, que si recordáis, se crea en un momento dado con los valores de las variables que indican dónde está instalado Hadoop).\n",
    "\n",
    "Esto hará que cambie lo que el *shell* nos muestra y ahora sea:\n",
    "\n",
    "```bash\n",
    "hdadmin@namenode:~$\n",
    "```\n",
    "\n",
    "Los servicios que se ejecutan dentro de cada contenedor que pertenecen a Hadoop son normalmente servicios java, por lo que con la utilidad `jps` se puede comprobar cuáles tenemos en ejecución. Si no tenemos los servicios que se esperan, puede haber un error en la ejecución o en cómo se construyó el contenedor. Como usuario `hdadmin` (**ESTO ES MUY IMPORTANTE**), hay que ejecutar la utilidad `jps`:\n",
    "\n",
    "```bash\n",
    "$ docker exec -ti datanode1 bash\n",
    "root@datanode1:/# su - hdadmin\n",
    "hdadmin@datanode1:~$ jps\n",
    "306 Jps\n",
    "101 NodeManager\n",
    "40 DataNode\n",
    "```\n",
    "\n",
    "Nótese cómo se cambia al usuario `hdadmin`, y después se ejecuta `jps`. Nótese también cómo en el datanode tienen que estar funcionando el `NodeManager` (gestor del nodo de cara a YARN para asignación de recursos) y el `DataNode` (programa que permite a HDFS almacenar bloques de ficheros).\n",
    "\n",
    "En el caso del namenode habrá más servicios en ejecución.\n",
    "\n",
    "Para salir del contenedor hay que escribir `exit` dos veces: una saldrá del usuario `hdadmin` de vuelta hacia `root`, y el último `exit` saldrá del `exec` hacia el contenedor (aunque el contenedor continúa ejecutándose en segundo plano):\n",
    "\n",
    "```bash\n",
    "hdadmin@namenode:~$ exit\n",
    "logout\n",
    "root@namenode:/# exit\n",
    "exit\n",
    "usuario-linux-host:dir$ \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90410705-8adc-4ee2-a41b-e941863f5e11",
   "metadata": {},
   "source": [
    "## Comprobación por web de los servicios\n",
    "\n",
    "Recordad que Hadoop ofrece unas direcciones que se pueden acceder a través del navegador. Podéis usarlas para comprobar los nodos disponibles, el estado de HDFS, etc. A veces la actualización de nuevos nodos o nuevos caídos puede tardar hasta 5 o 10 minutos.\n",
    "\n",
    "- http://localhost:9870 interfaz web del HDFS\n",
    "- http://localhost:8088 interfaz web de YARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c4ae0-e212-41e2-838d-ae84ab18a815",
   "metadata": {},
   "source": [
    "## Comprobación de los servicios con las utilidades de Hadoop\n",
    "\n",
    "Normalmente dentro del `namenode`, se pueden usasr las utilidades de Hadoop para comprobar los nodos conectados y el estado de HDFS:\n",
    "\n",
    "```bash\n",
    "$ docker exec -ti namenode bash\n",
    "root@namenode:/# su - hdadmin\n",
    "hdadmin@namenode:~$ hdfs dfsadmin -report\n",
    "...\n",
    "hdadmin@namenode:~$ yarn node -list\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6530c6a8-5f30-45c2-beca-cc7d1ca78bdd",
   "metadata": {},
   "source": [
    "## Refresco de los nodos al añadir o eliminar\n",
    "\n",
    "En puntos de la práctica, tenéis que añadir y eliminar nodos. Para forzar que Hadoop los reconsidere, hay dos funciones a utilizar, siempre como el usuario `hdadmin`:\n",
    "\n",
    "```bash\n",
    "hdadmin@namenode:~$ hdfs dfsadmin -refreshNodes\n",
    "hdadmin@namenode:~$ yarn rmadmin -refreshNodes\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
