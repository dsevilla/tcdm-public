{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7339d12",
   "metadata": {},
   "source": [
    "# TCDM Práctica 3: MapReduce con *datasets* reales (StackOverflow), curso 25-26.\n",
    "\n",
    "**Objetivo**: Implementar algoritmos de MapReduce usando **MrJob** para analizar datos reales de StackOverflow.\n",
    "\n",
    "### Descarga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95248775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_619974/1726189557.py:17: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extract(member)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# URLs de descarga\n",
    "file: str = \"stackoverflow.csv.tar.gz\"\n",
    "URL: str = f\"https://github.com/dsevilla/bd2-data/releases/download/parquet-files-25-26/{file}\"\n",
    "\n",
    "# Descargar el fichero tar.gz\n",
    "urllib.request.urlretrieve(URL, file)\n",
    "assert os.path.isfile(file), f\"Error: {file} no se ha descargado correctamente.\"\n",
    "\n",
    "# Extraer archivos\n",
    "with tarfile.open(\"stackoverflow.csv.tar.gz\", \"r:gz\") as tar:\n",
    "    for member in tar.getmembers():\n",
    "        if member.name.endswith((\"Posts.csv\", \"Users.csv\")):\n",
    "            tar.extract(member)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed7a0e",
   "metadata": {},
   "source": [
    "## Configuración inicial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0950bae0",
   "metadata": {},
   "source": [
    "La configuración inicial incluye la creación de un entorno virtual (si no lo tenéis creado ya) y la descargar de los paquetes necesarios.\n",
    "\n",
    "> **OJO**: Todo esto hay que hacerlo **dentro del contenedor `namenode`, como usuario `luser`**, que es el encargado de lanzar los trabajos MapReduce como un usuario normal.\n",
    "\n",
    "```bash\n",
    "test -e ~/.venv || python3 -m venv ~/.venv\n",
    ". ~/.venv/bin/activate\n",
    "# Descargar requirements\n",
    "wget -q https://github.com/dsevilla/tcdm-public/raw/25-26/practicas/p3/requirements.txt\n",
    "cat requirements.txt\n",
    "# Instalar requirements\n",
    "pip3 install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d8bdc",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Contar cuántas respuestas tiene cada pregunta, después devolverlas ordenadas por número de respuestas\n",
    "\n",
    "**Entrada**: `Posts.csv`\n",
    "\n",
    "**Salida**: `(pregunta_id, número_respuestas)`\n",
    "\n",
    "**Lógica**: \n",
    "- Las respuestas tienen `PostTypeId=2` \n",
    "- El `ParentId` de una respuesta apunta a la pregunta\n",
    "- Contar agrupando por `ParentId`\n",
    "\n",
    "**Ejercicio**: Terminar la implementación en `p3_so_count_answers.py`:\n",
    "\n",
    "```bash\n",
    "python3 so_count_answers.py Posts.csv > so_count_answers.out\n",
    "# (o bien si se ejecuta dentro del clúster Hadoop)\n",
    "python3 so_count_answers.py -r hadoop hdfs://namenode:9000/user/luser/.../Posts.csv > so_count_answers.out\n",
    "```\n",
    "\n",
    "### El problema de la ordenación:\n",
    "\n",
    "El resultado anterior no está ordenado. ¿Por qué? Dentro de cada reducer, las claves están ordenadas lexicográficamente, pero la salida global concatena resultados de múltiples reducers sin garantía de orden. Para obtener las preguntas con más respuestas en un resultado ordenado, tenemos varias opciones:\n",
    "\n",
    "- Ordenar como último paso con un programa externo. Esto tiene el problema de que necesitamos otra herramienta externa, tipo `sort` de UNIX/Linux o hacerlo en `pandas`, etc. Se puede realizar, pero tiene el problema de que no es escalable.\n",
    "\n",
    "- Hacer dos pasos de MapReduce. En el primer paso contamos las respuestas, y en el segundo ordenamos los resultados. Para ello debemos especificar que sólo hay un *reducer*, que recibe todas las claves y puede ordenarlas y escribirlas ordenadas como resultado. Problema: ¿Qué pasa si el resultado es muy grande? Un sólo *reducer* puede no ser capaz de tratar todos los datos. En general esto no es un problema, porque los trabajos de MapReduce suelen reducir mucho el tamaño de los datos. Pero es un problema a tener en cuenta. En nuestro caso lo será, porque si hay millones de preguntas, el resultado puede ser muy grande.\n",
    "\n",
    "- Hacer un Top-K integrado. En este caso, cada *mapper* y *reducer* mantiene una lista de los K elementos más grandes que ha visto. Se elige un conjunto de *buckets* tal que la división en esos *buckets* no llega a ser más grande que la memoria. Cada uno de los *reducers* calcula su top-k. Al final, un único *reducer* recibe las listas de los demás y calcula el Top-K global. Esto es escalable, porque el tamaño del resultado es siempre K, que es pequeño. El problema es que no obtenemos el resultado completo, sólo los K primeros.\n",
    "\n",
    "En general la ordenación no es un problema, porque lo que queremos es que se produzcan **todos los resultados correctos**, no el orden.\n",
    "\n",
    "Veamos cómo cambiar el programa para implementar estas opciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d72cba",
   "metadata": {},
   "source": [
    "#### Dos pasos MapReduce para ordenar\n",
    "\n",
    "Cambia el programa `p3_so_count_answers.py` para hacer dos pasos de MapReduce y ordenar el resultado:\n",
    "\n",
    "```bash\n",
    "python3 so_count_answers_ordered.py Posts.csv > respuestas_ordenadas.out\n",
    "```\n",
    "\n",
    "#### Top-K\n",
    "\n",
    "Cambia el programa `p3_so_count_answers.py` para implementar el Top-K. El programa debe aceptar dos parámetros: `--top-k` (número de elementos a devolver) y `--num-buckets` (número de *buckets* para dividir los datos). Por ejemplo, para obtener las 20 preguntas con más respuestas usando 100 *buckets*:\n",
    "\n",
    "```bash\n",
    "python3 so_count_answers_topk.py --top-k=20 --num-buckets=100 Posts.csv > top20_respuestas.out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a19ad3b",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Filtrado y agregación\n",
    "\n",
    "**Objetivo**: Contar preguntas agrupadas por año y etiqueta.\n",
    "\n",
    "**Entrada**: `Posts.csv`\n",
    "\n",
    "**Salida**: `((año, etiqueta), número_preguntas)`\n",
    "\n",
    "**Lógica**:\n",
    "- Filtrar solo preguntas (`PostTypeId=1`)\n",
    "- Extraer año de `CreationDate` \n",
    "- Parsear etiquetas del campo `Tags` (formato: `<python><pandas><web>`)\n",
    "- Contar por cada par (año, etiqueta)\n",
    "\n",
    "**Ejecución**:\n",
    "\n",
    "```bash\n",
    "python3 so_bytagyear.py Posts.csv > preguntas_por_tag_año.out\n",
    "```\n",
    "\n",
    "**Salida esperada**:\n",
    "```\n",
    "(2020,python)     245\n",
    "(2019,javascript) 189\n",
    "(2021,java)       156\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aa392a",
   "metadata": {},
   "source": [
    "## Ejercicio 3: JOIN simple\n",
    "\n",
    "**Objetivo**: Relacionar preguntas con la reputación de sus autores.\n",
    "\n",
    "**Entrada**: `Posts.csv` y `Users.csv`\n",
    "\n",
    "**Salida**: `(pregunta_id, (reputación_autor, nombre_autor))`\n",
    "\n",
    "**Lógica**:\n",
    "- Map-side join: usar prefijos para distinguir tipos de entrada\n",
    "- Crear archivos prefijados: `P|<línea_post>` y `U|<línea_user>`\n",
    "- En mapper: agrupar por `OwnerUserId`\n",
    "- En reducer: combinar datos de usuario y preguntas\n",
    "\n",
    "**Preparación**:\n",
    "```bash\n",
    "sed 's/^/P|/' Posts.csv > Posts_prefixed.csv\n",
    "sed 's/^/U|/' Users.csv > Users_prefixed.csv\n",
    "```\n",
    "\n",
    "> **OJO**: Si se ejecuta en Hadoop, hay que copiar los archivos a HDFS:\n",
    "> ```bash\n",
    "> hdfs dfs -put Posts_prefixed.csv /user/luser/...\n",
    "> hdfs dfs -put Users_prefixed.csv /user/luser/...\n",
    "> ```\n",
    "\n",
    "**Ejecución**:\n",
    "\n",
    "```bash\n",
    "python3 so_join.py Posts_prefixed.csv Users_prefixed.csv > pregunta_reputacion.out\n",
    "```\n",
    "\n",
    "**Salida esperada**:\n",
    "```\n",
    "495829        (39,Daniel)\n",
    "496121        (39,Daniel)\n",
    "496183        (39,Daniel)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d93b3",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Coocurrencia de etiquetas\n",
    "\n",
    "**Objetivo**: Encontrar pares de etiquetas que aparecen juntas frecuentemente.\n",
    "\n",
    "**Entrada**: `Posts.csv`\n",
    "\n",
    "**Salida**: `((etiqueta1, etiqueta2), frecuencia)`\n",
    "\n",
    "**Lógica**:\n",
    "- Para cada pregunta extraer sus múltiples etiquetas\n",
    "- Generar todas las combinaciones de pares \n",
    "- Contar frecuencia de cada par\n",
    "\n",
    "**Ejecución**:\n",
    "\n",
    "```bash\n",
    "python3 so_tagcooc.py Posts.csv > coocurrencia_tags.out\n",
    "```\n",
    "\n",
    "**Salida esperada**:\n",
    "```\n",
    "python,pandas     89\n",
    "javascript,html   76\n",
    "java,spring       54\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8ebbf",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Análisis temporal avanzado\n",
    "\n",
    "**Objetivo**: Evolución de popularidad de tecnologías en el tiempo.\n",
    "\n",
    "**Paso 1**: Actividad por tecnología y mes\n",
    "- **Entrada**: `Posts.csv`\n",
    "- **Salida temporal**: `((etiqueta, año-mes), actividad)` donde actividad = preguntas + respuestas × 0.5\n",
    "\n",
    "**Paso 2**: Calcular tendencias (crecimiento mes a mes)\n",
    "- **Entrada**: actividad del paso 1\n",
    "- **Salida temporal**: `((etiqueta, mes), delta_actividad)`\n",
    "\n",
    "**Paso 3**: Clasificar tecnologías por tendencia\n",
    "- **Entrada**: tendencias del paso 2\n",
    "- **Criterio**: promedio de delta últimos 6 meses\n",
    "- **Salida final**: tecnologías en crecimiento/declive\n",
    "\n",
    "**Ejecución**:\n",
    "\n",
    "```bash\n",
    "python3 so_tecnology_evolution.py Posts.csv > evolucion_tecnologias.out\n",
    "```\n",
    "\n",
    "**Salida esperada**:\n",
    "\n",
    "Tag, tendencia, promedio_delta (con 1 decimal, el signo sólo en los negativos), meses_considerados. Todo separado por tabuladores.\n",
    "\n",
    "```\n",
    "apache  CRECIMIENTO     92.3    6\n",
    "apache-cordova  DECLIVE -8.3    6\n",
    "apache-netbeans CRECIMIENTO     19.4    6\n",
    "apache-pdfbox   ESTABLE 0.0     3\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c58b27",
   "metadata": {},
   "source": [
    "## Evaluación y entrega\n",
    "\n",
    "### Criterios de evaluación\n",
    "\n",
    "Se tendrá en cuenta, por orden de importancia: Que el código funcione correctamente y produzca los resultados esperados; que se usen buenas prácticas de programación y eficiencia en MapReduce; y que el código tenga suficientes comentarios y esté bien estructurado. Se valorará positivamente la construcción de tests para probar que los ejercicios funcionan correctamente.\n",
    "\n",
    "### Entrega\n",
    "\n",
    "Entregar en la tarea del Aula Virtual un archivo comprimido `.zip` o `.tar.gz` con el código fuente de los ejercicios realizados y un pequeño informe explicando qué se ha realizado en cada paso de Map-Reduce para cada ejercicio. Opcionalmente, se pueden incluir programas de prueba (*unit tests*) para verificar el correcto funcionamiento de los ejercicios (se muestra un ejemplo en las plantillas de código más abajo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc48d2",
   "metadata": {},
   "source": [
    "## ANEXO: Plantillas de código\n",
    "\n",
    "A continuación se muestran plantillas útiles para empezar los ejercicios. Nótese cómo, para evitar problemas con los datos, se utiliza la propia librería `csv` de Python para parsear las líneas de entrada (aunque sea sólo una línea, que es lo que recibe cada llamada al *mapper*).\n",
    "\n",
    "Las clases `TextValueProtocol` y `TextProtocol` permiten que los datos de entrada y salida se traten como texto plano, evitando problemas con los tipos por defecto de `mrjob`. En general, como la salida será normalmente una clave de texto y un valor de texto separados por tabulador, este formato acepta cadenas de caracteres y produce el resultado correcto.\n",
    "\n",
    "En los pasos intermedios, MrJob, al utilizar Hadoop (que trata todo en binario), se pueden utilizar como claves y valores tipos estándar de python como tuplas, listas, arrays, etc. (se puede ver en los ejemplos de más abajo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042ffb0",
   "metadata": {},
   "source": [
    "### Plantilla básica MRJob\n",
    "\n",
    "```python\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.protocol import TextProtocol, TextValueProtocol\n",
    "import csv\n",
    "\n",
    "class MiEjercicio(MRJob):\n",
    "    INPUT_PROTOCOL = TextValueProtocol\n",
    "    OUTPUT_PROTOCOL = TextProtocol\n",
    "    \n",
    "    def mapper(self, key, value):\n",
    "        \"\"\"Procesar cada línea del CSV\"\"\"\n",
    "        try:\n",
    "            row = next(csv.reader([value]))\n",
    "            \n",
    "            # Skip header\n",
    "            if row and row[0].strip().lower() == 'id':\n",
    "                return\n",
    "                \n",
    "            # Extraer campos necesarios\n",
    "            campo1 = row[POSICION].strip()\n",
    "            \n",
    "            # Lógica del ejercicio\n",
    "            if condicion:\n",
    "                yield clave, valor\n",
    "                \n",
    "        except (ValueError, IndexError, csv.Error):\n",
    "            return  # Ignorar líneas malformadas\n",
    "    \n",
    "    def combiner(self, key, values):\n",
    "        \"\"\"Combinar localmente (opcional pero recomendado)\"\"\"\n",
    "        yield key, ...\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        \"\"\"Agregación final\"\"\"\n",
    "        # Realizar cálculos\n",
    "        # ...\n",
    "        yield key, ...\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MiEjercicio.run()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a36ebd7",
   "metadata": {},
   "source": [
    "### Plantilla para ejercicios multi-paso\n",
    "\n",
    "```python\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "# Paso 1\n",
    "class MiEjercicio(MRJob):\n",
    "\n",
    "    def steps(self) -> list[MRStep]:\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper1,\n",
    "                    reducer=self.reducer1),\n",
    "            MRStep(mapper=self.mapper2,\n",
    "                    reducer=self.reducer2),\n",
    "            ...  # Más pasos si es necesario\n",
    "        ]\n",
    "\n",
    "    def mapper1(self, key, value):\n",
    "        # Procesar datos originales\n",
    "        yield clave_intermedia, valor_intermedio\n",
    "    \n",
    "    def reducer1(self, key, values):\n",
    "        yield key, proceso(values)\n",
    "\n",
    "    # Paso 2\n",
    "    def mapper2(self, key, value):\n",
    "        # Procesar salida del paso 1\n",
    "        yield nueva_clave, nuevo_valor\n",
    "\n",
    "    def reducer2(self, key, values):\n",
    "        yield key, agregacion_final(values)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b88f5",
   "metadata": {},
   "source": [
    "### Ejemplo de construcción de tests\n",
    "\n",
    "Para realizar los tests, supondremos que tenemos la salida de cada ejercicio en su fichero `.out`. Primero, hay que asegurarse de que se tiene instalado `pandas` y `pytest` en el entorno virtual:\n",
    "\n",
    "```bash\n",
    "pip install pandas pytest\n",
    "```\n",
    "\n",
    "El archivo de ejemplo `test_ejercicio1.py` muestra cómo comparar la salida del ejercicio 1 con una implementación de referencia usando `pandas`:\n",
    "\n",
    "```python\n",
    "# test_count_answers.py\n",
    "from pandas import DataFrame, Series, read_csv, notna\n",
    "\n",
    "\n",
    "def test_so_count_answers() -> None:\n",
    "    \"\"\"Compara so_count_answers.py con implementación pandas de referencia\"\"\"\n",
    "    output_file: str = \"so_count_answers.out\"\n",
    "    posts_file: str = \"Posts.csv\"\n",
    "\n",
    "    # Usar el resultado del fichero generado previamente\n",
    "    mrjob_results: DataFrame = read_csv(\n",
    "        output_file, sep=\"\\t\", header=None, names=[\"QuestionId\", \"AnswerCount\"]\n",
    "    )\n",
    "\n",
    "    # Implementación de referencia con pandas\n",
    "    df: DataFrame = read_csv(posts_file)\n",
    "\n",
    "    # Filtrar respuestas (PostTypeId = 2) con ParentId válido\n",
    "    answers: DataFrame = df[df[\"PostTypeId\"] == 2]\n",
    "\n",
    "    # Contar respuestas por pregunta (ParentId ya es el índice)\n",
    "    answer_counts: Series = answers[\"ParentId\"].value_counts(sort=False)\n",
    "\n",
    "    # Comparar resultados\n",
    "    assert len(mrjob_results) == len(\n",
    "        answer_counts\n",
    "    ), f\"Diferente número de preguntas: MRJob={len(mrjob_results)}, Pandas={len(answer_counts)}\"\n",
    "\n",
    "    for question_id, mrjob_count in mrjob_results.itertuples(index=False):\n",
    "        pandas_count: int = answer_counts.get(question_id, 0)\n",
    "        assert (\n",
    "            mrjob_count == pandas_count\n",
    "        ), f\"Diferencia en pregunta {question_id}: MRJob={mrjob_count}, Pandas={pandas_count}\"\n",
    "\n",
    "    # Verificar que el campo AnswerCount de cada pregunta coincide con el conteo real\n",
    "    questions: DataFrame = df[df[\"PostTypeId\"] == 1]\n",
    "    questions_with_answers: DataFrame = questions[questions[\"Id\"].isin(answer_counts.index)]\n",
    "\n",
    "    for _, question in questions_with_answers.iterrows():\n",
    "        question_id: int = int(question[\"Id\"])\n",
    "        declared_count: int = int(question[\"AnswerCount\"]) if notna(question[\"AnswerCount\"]) else 0\n",
    "        actual_count: int = answer_counts.get(question_id, 0)\n",
    "\n",
    "        assert declared_count == actual_count, (\n",
    "            f\"El campo AnswerCount no coincide para pregunta {question_id}: \"\n",
    "            f\"AnswerCount={declared_count}, conteo real={actual_count}\"\n",
    "        )\n",
    "\n",
    "    print(f\"Comparación exitosa: {len(mrjob_results)} preguntas con respuestas\")\n",
    "    print(f\"Verificación AnswerCount: {len(questions_with_answers)} preguntas verificadas\")\n",
    "```\n",
    "\n",
    "Finalmente, para probarlo:\n",
    "\n",
    "```bash\n",
    "pytest test_count_answers.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
