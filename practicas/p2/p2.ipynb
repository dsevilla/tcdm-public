{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5060f5fa-5063-4ac1-9e3a-e0132d686ed4",
   "metadata": {},
   "source": [
    "# Práctica 2: Acceso y gestión de HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9dfdc-e7ca-4bca-a627-69f37873e12e",
   "metadata": {},
   "source": [
    "En esta práctica veremos cómo acceder programáticamente y gestionar el HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214beb8c-c4ae-4644-907c-b29c8e341a32",
   "metadata": {},
   "source": [
    "## Primera parte: ejecución del código `filesystem_cat` (ver transparencias tema 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee0571d-95ca-4e62-bcbc-55887c0cabc4",
   "metadata": {},
   "source": [
    "1. Descarga el fichero adjunto [`filesystem_cat.py`](https://github.com/dsevilla/tcdm-public/raw/24-25/practicas/p2/filesystem_cat.py).\n",
    "2. Súbelo al contenedor `namenode` en el directorio del usuario `luser`:\n",
    "```bash\n",
    "docker cp filessytem_cat.py namenode:/home/luser\n",
    "```\n",
    "3. En el `namenode`, como usuario `luser` (`su - luser`):\n",
    "4. Para ejecutarlo, hay que hacer unos pasos iniciales:\n",
    "   - Instalar el paquete `pyarrow`:\n",
    "    ```bash\n",
    "    pip install pyarrow\n",
    "    ```\n",
    "   - Establecer correctamente la variable de entorno CLASSPATH:\n",
    "    ```bash\n",
    "    export CLASSPATH=$(hdfs classpath --glob)\n",
    "    ```\n",
    "5. Comprueba que es capaz de mostrar algún fichero de texto (sin comprimir) que subáis a HDFS, como se hizo en la práctica 1 co los libros, por ejemplo:\n",
    "\n",
    "```bash\n",
    "python3 filesystem_cat.py hdfs://namenode:9000/fichero/a/mostrar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c54256-8b77-4d20-8e07-17aadef5f886",
   "metadata": {},
   "source": [
    "## Segunda parte: código `copy_half_file` (ver transparencias tema 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f21f1-62f8-4339-a070-418eafc1eb2e",
   "metadata": {},
   "source": [
    "1. Basándote en el código anterior y en la plantilla adjunta [`copy_half_file.py`](https://github.com/dsevilla/tcdm-public/raw/24-25/practicas/p2/copy_half_file.py), escribe un programa que copie la mitad inferior del fichero en HDFS a otro fichero en otro directorio del HDFS\n",
    "   - Usa `get_file_info()` para obtener la longitud del fichero y `seek()` para saltar a la mitad del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dcbcbd-d920-4fc3-8295-fe16a13bf2fa",
   "metadata": {},
   "source": [
    "## Tercera parte: Probar el comandos `hdfs dfsadmin`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10756d64-83ab-4753-9bc8-ea360c9af1b4",
   "metadata": {},
   "source": [
    "1. En el NameNode, como usuario `hdadmin`, crea un directorio en HDFS y ponle una cuota de solo 4 ficheros. Comprueba cuántos ficheros puedes copiar a ese directorio. Explica a qué se debe este comportamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734d522-80e5-4dd5-a69b-e3b7c4ae71ed",
   "metadata": {},
   "source": [
    "## Cuarta parte: Probar el comando `hdfs fsck`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82caac8-4919-4f3a-9c54-2f19ac411c22",
   "metadata": {},
   "source": [
    "1. En el NameNode (como usuario `hdadmin`) haz un chequeo de todo el HDFS, y comprueba si te da errores:\n",
    "  - Intenta determinar las causas de los posibles errores\n",
    "2. Detén docker datanodes de forma brusca (sin detener los demonios, simplemente haciendo p.e. `docker container stop datanode2 datanode3`) hasta que te queden solo 2 datanodes levantados. Espera unos 10 minutos[1] y comprueba que el comando `hdfs dfsadmin -report` muestra que solo quedan 2 datanodes vivos.\n",
    "3. Realiza de nuevo el chequeo de disco en el NameNode y comprueba la salida. ¿Cuántos bloques aparecen under-replicated?\n",
    "4. Prueba a hacer un get del fichero `random_words.txt.bz2` para ver si se hace correctamente.\n",
    "5. Sigue los pasos que viste en la práctica 1 para añadir un datanode nuevo (vacío). Comprueba, haciendo de nuevo el chequeo, que los datos se replican en el nuevo nodo hasta alcanzar el factor de replicación por defecto.\n",
    "\n",
    "[1] El tiempo depende de los parámetros `dfs.namenode.stale.datanode.interval` y `dfs.namenode.heartbeat.recheck-interval`. El primero indica el tiempo sin detectar actividad del DataNode para que el NameNode lo considere en estado stale (por defecto, 30 segundos).  Un nodo en estado stale tiene menor prioridad en lecturas y escrituras. El segundo parámetro  indica el  intervalo de chequeo en busca de DataNodes expirados (valor por defecto, 5 minutos). Un DataNode se pasa al estado Dead cuando el tiempo sin detectar actividad es superior a `dfs.namenode.stale.datanode.interval + 2 * dfs.namenode.heartbeat.recheck-interval`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1e687-0056-428d-b2fc-8ef3e3a8e424",
   "metadata": {},
   "source": [
    "## Entrega"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968bc696-9877-42dc-87d6-8fc4bb603245",
   "metadata": {},
   "source": [
    "1. Entregar el código desarrollado en la segunda parte, todos los ficheros `*.py`, y un ejemplo de su ejecución.\n",
    "2. Un documento que muestre que se han ejecutado las tercera y cuarta partes. Mostrar capturas de pantalla, incluyendo una explicación y justificación de lo que aparece en las mismas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
