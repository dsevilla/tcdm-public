{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5060f5fa-5063-4ac1-9e3a-e0132d686ed4",
   "metadata": {},
   "source": [
    "# Práctica 2:\n",
    "# Acceso y gestión de HDFS, 25-26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9dfdc-e7ca-4bca-a627-69f37873e12e",
   "metadata": {},
   "source": [
    "En esta práctica veremos cómo acceder programáticamente y gestionar el HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed15c07",
   "metadata": {},
   "source": [
    "> ### Inciso: Instalación de paquetes de Python en las máquinas del clúster\n",
    ">\n",
    "> En general, la instalación de paquetes de Python se hace con `pip3`. Para crear paquetes por parte del usuario, es necesario crear un entorno virtual para que el usuario pueda crear un entorno controlado y propio. Para ello, se puede usar el módulo `venv` de Python:\n",
    ">\n",
    "> ```bash\n",
    "> python3 -m venv ~/.venv\n",
    "> . ~/.venv/bin/activate\n",
    "> pip3 install -r requirements.txt\n",
    "> ...\n",
    "> pip3 install paquete1 paquete2 ...\n",
    "> ```\n",
    ">\n",
    "> La segunda línea activa el entorno virtual. Nótese que el *prompt* cambia a algo como:\n",
    ">\n",
    "> ```bash\n",
    "> (.venv) usuario@ordenador:directorio$ _\n",
    "> ```\n",
    ">\n",
    "> indicándonos que estamos usando el entorno virtual de ejecución (`.venv`). Un entorno virtual permite instalar un conjunto de paquetes propio para cada usuario.\n",
    ">\n",
    "> Después, cada vez que se entre al usuario, para recuperar el entorno de ejecución habrá que hacer:\n",
    "> ```bash\n",
    "> . ~/.venv/bin/activate\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214beb8c-c4ae-4644-907c-b29c8e341a32",
   "metadata": {},
   "source": [
    "## Primera parte: ejecución del código `filesystem_cat` (véanse las transparencias del Tema 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee0571d-95ca-4e62-bcbc-55887c0cabc4",
   "metadata": {},
   "source": [
    "1. Descarga el fichero adjunto `filesystem_cat.py`: https://github.com/dsevilla/tcdm-public/raw/25-26/practicas/p2/filesystem_cat.py en el contenedor `namenode` con el usuario `luser` (`su - luser`):\n",
    "    ```bash\n",
    "    cd; wget https://github.com/dsevilla/tcdm-public/raw/25-26/practicas/p2/filesystem_cat.py\n",
    "    ```\n",
    "\n",
    "2. Para ejecutarlo, hay que hacer unos pasos iniciales:\n",
    "   - Instalar el paquete `pyarrow` (recordad que hay que hacerlo dentro del entorno virtual):\n",
    "    ```bash\n",
    "    pip3 install pyarrow\n",
    "    ```\n",
    "   - Establecer correctamente la variable de entorno `CLASSPATH`:\n",
    "    ```bash\n",
    "    export CLASSPATH=\"$(hadoop classpath --glob):$CLASSPATH\"\n",
    "    ```\n",
    "    (esto lo podéis añadir al final del fichero `~/.bashrc` para que se establezca automáticamente al iniciar sesión).\n",
    "5. Comprueba que es capaz de mostrar algún fichero de texto (sin comprimir) que subáis a HDFS, como se hizo en la práctica 1 con los libros, por ejemplo:\n",
    "    ```bash\n",
    "    python3 filesystem_cat.py hdfs://namenode:9000/fichero/a/mostrar\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c54256-8b77-4d20-8e07-17aadef5f886",
   "metadata": {},
   "source": [
    "## Segunda parte: código `copy_half_file` (véanse las transparencias del Tema 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f21f1-62f8-4339-a070-418eafc1eb2e",
   "metadata": {},
   "source": [
    "1. Basándote en el código anterior y en la plantilla adjunta `copy_half_file.py`: https://github.com/dsevilla/tcdm-public/raw/25-26/practicas/p2/copy_half_file.py, escribe un programa que copie la mitad inferior del fichero en HDFS a otro fichero en otro directorio del HDFS\n",
    "   - Usa `get_file_info()` para obtener la longitud del fichero y `seek()` para saltar a la mitad del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dcbcbd-d920-4fc3-8295-fe16a13bf2fa",
   "metadata": {},
   "source": [
    "## Tercera parte: Probar el comandos `hdfs dfsadmin`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10756d64-83ab-4753-9bc8-ea360c9af1b4",
   "metadata": {},
   "source": [
    "1. En el NameNode, como usuario `hdadmin`, crea un directorio en HDFS y ponle una cuota de solo 4 ficheros. Comprueba cuántos ficheros puedes copiar a ese directorio. Explica a qué se debe este comportamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734d522-80e5-4dd5-a69b-e3b7c4ae71ed",
   "metadata": {},
   "source": [
    "## Cuarta parte: Probar el comando `hdfs fsck`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82caac8-4919-4f3a-9c54-2f19ac411c22",
   "metadata": {},
   "source": [
    "1. En el NameNode (como usuario `hdadmin`) haz un chequeo de todo el HDFS, y comprueba si te da errores:\n",
    "  - Intenta determinar las causas de los posibles errores\n",
    "2. Detén docker datanodes de forma brusca (sin detener los demonios, simplemente haciendo p.e. `docker container stop datanode2 datanode3`) hasta que te queden solo 2 datanodes levantados. Espera unos 10 minutos[1] y comprueba que el comando `hdfs dfsadmin -report` muestra que solo quedan 2 datanodes vivos.\n",
    "3. Realiza de nuevo el chequeo de disco en el NameNode y comprueba la salida. ¿Cuántos bloques aparecen under-replicated?\n",
    "4. Prueba a hacer un get del fichero `random_words.txt.bz2` para ver si se hace correctamente.\n",
    "5. Sigue los pasos que viste en la práctica 1 para añadir un datanode nuevo (vacío). Comprueba, haciendo de nuevo el chequeo, que los datos se replican en el nuevo nodo hasta alcanzar el factor de replicación por defecto.\n",
    "\n",
    "[1] El tiempo depende de los parámetros `dfs.namenode.stale.datanode.interval` y `dfs.namenode.heartbeat.recheck-interval`. El primero indica el tiempo sin detectar actividad del DataNode para que el NameNode lo considere en estado stale (por defecto, 30 segundos).  Un nodo en estado stale tiene menor prioridad en lecturas y escrituras. El segundo parámetro  indica el  intervalo de chequeo en busca de DataNodes expirados (valor por defecto, 5 minutos). Un DataNode se pasa al estado Dead cuando el tiempo sin detectar actividad es superior a `dfs.namenode.stale.datanode.interval + 2 * dfs.namenode.heartbeat.recheck-interval`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1e687-0056-428d-b2fc-8ef3e3a8e424",
   "metadata": {},
   "source": [
    "## Entrega"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968bc696-9877-42dc-87d6-8fc4bb603245",
   "metadata": {},
   "source": [
    "1. Entregar el código desarrollado en la segunda parte, todos los ficheros `*.py`, y un ejemplo de su ejecución.\n",
    "2. Un documento que muestre que se han ejecutado la tercera y cuarta partes. Mostrar capturas de pantalla, incluyendo una explicación y justificación de lo que aparece en las mismas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
